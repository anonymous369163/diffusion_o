"""
æ‰©æ•£æ¨¡å‹ + å¼ºåŒ–å­¦ä¹ çš„TSPè®­ç»ƒå™¨
ç»“åˆdifuscoæ‰©æ•£æ¨¡å‹å’ŒPOMOå¼ºåŒ–å­¦ä¹ æ–¹æ³•
"""

import sys
import os
import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
from argparse import ArgumentParser
from logging import getLogger
import logging
from torch.optim import Adam as Optimizer
from torch.optim.lr_scheduler import MultiStepLR as Scheduler

# æ·»åŠ TensorBoardç›¸å…³å¯¼å…¥
from torch.utils.tensorboard import SummaryWriter
import time
from collections import deque

# å¯¼å…¥æ‰©æ•£æ¨¡å‹ç›¸å…³
sys.path.append('/root/code/difusco_o/difusco_o/DIFUSCO/difusco')
from difusco.utils.diffusion_schedulers import InferenceSchedule
# from difusco.pl_tsp_model import TSPModel
# from difusco.utils.draw_utils import visualize_tsp_solutions

# å¯¼å…¥å¼ºåŒ–å­¦ä¹ ç›¸å…³
sys.path.append('/root/code/diffusco_o/difusco_o/DIFUSCO/mtnco/MTPOMO/POMO')
from mtnco.utils.utils import *


class TSPEnv:
    """TSPç¯å¢ƒï¼ŒåŸºäºæ‰©æ•£æ¨¡å‹ç”Ÿæˆçš„é‚»æ¥çŸ©é˜µè¿›è¡Œå¼ºåŒ–å­¦ä¹ """
    
    def __init__(self, batch_size, num_nodes, pomo_size=None):
        self.batch_size = batch_size
        self.num_nodes = num_nodes
        self.pomo_size = pomo_size if pomo_size else num_nodes
        
        # çŠ¶æ€å˜é‡
        self.points = None
        self.adj_matrix = None
        self.visited_mask = None
        self.current_node = None
        self.tour = None
        self.tour_length = None
        self.done = None
        
        # æ‰¹æ¬¡å’ŒPOMOç´¢å¼•
        self.BATCH_IDX = torch.arange(self.batch_size)[:, None].expand(self.batch_size, self.pomo_size)
        self.POMO_IDX = torch.arange(self.pomo_size)[None, :].expand(self.batch_size, self.pomo_size)
        
    def reset(self, points, adj_matrix):
        """
        é‡ç½®ç¯å¢ƒçŠ¶æ€
        Args:
            points: (batch_size, num_nodes, 2) - èŠ‚ç‚¹åæ ‡
            adj_matrix: (batch_size, num_nodes, num_nodes) - æ‰©æ•£æ¨¡å‹ç”Ÿæˆçš„é‚»æ¥çŸ©é˜µ
        """
        self.points = points
        self.adj_matrix = adj_matrix
        
        # è·å–è®¾å¤‡ä¿¡æ¯ï¼Œç¡®ä¿æ‰€æœ‰å¼ é‡åœ¨åŒä¸€è®¾å¤‡ä¸Š
        device = points.device
        
        # åˆå§‹åŒ–çŠ¶æ€ï¼ˆç¡®ä¿åœ¨æ­£ç¡®çš„è®¾å¤‡ä¸Šï¼‰
        self.visited_mask = torch.zeros(self.batch_size, self.pomo_size, self.num_nodes, dtype=torch.bool, device=device)
        self.current_node = torch.zeros(self.batch_size, self.pomo_size, dtype=torch.long, device=device)
        self.tour = [torch.zeros(self.batch_size, self.pomo_size, dtype=torch.long, device=device)]
        self.tour_length = torch.zeros(self.batch_size, self.pomo_size, device=device)
        self.done = torch.zeros(self.batch_size, self.pomo_size, dtype=torch.bool, device=device)
        
        # ç¡®ä¿BATCH_IDXå’ŒPOMO_IDXä¹Ÿåœ¨æ­£ç¡®çš„è®¾å¤‡ä¸Š
        self.BATCH_IDX = torch.arange(self.batch_size, device=device)[:, None].expand(self.batch_size, self.pomo_size)
        self.POMO_IDX = torch.arange(self.pomo_size, device=device)[None, :].expand(self.batch_size, self.pomo_size)
        
        # æ ‡è®°èµ·å§‹èŠ‚ç‚¹ä¸ºå·²è®¿é—® - é¿å…åŸåœ°æ“ä½œ
        new_visited_mask = self.visited_mask.clone()
        new_visited_mask[self.BATCH_IDX, self.POMO_IDX, self.current_node] = True
        self.visited_mask = new_visited_mask
        
        return self.get_state()
    
    def step(self, action):
        """
        æ‰§è¡ŒåŠ¨ä½œ
        Args:
            action: (batch_size, pomo_size) - é€‰æ‹©çš„ä¸‹ä¸€ä¸ªèŠ‚ç‚¹
        """
        # æ›´æ–°å½“å‰èŠ‚ç‚¹
        prev_node = self.current_node.clone()
        self.current_node = action
        
        # è®¡ç®—ç§»åŠ¨è·ç¦»ï¼ˆåŸºäºçœŸå®æ¬§å‡ é‡Œå¾—è·ç¦»ï¼‰
        step_distance = self.calculate_distance(prev_node, self.current_node)
        self.tour_length += step_distance
        
        # æ ‡è®°èŠ‚ç‚¹ä¸ºå·²è®¿é—® - é¿å…åŸåœ°æ“ä½œ
        new_visited_mask = self.visited_mask.clone()
        new_visited_mask[self.BATCH_IDX, self.POMO_IDX, self.current_node] = True
        self.visited_mask = new_visited_mask
        
        # æ·»åŠ åˆ°è·¯å¾„
        self.tour.append(self.current_node.clone())
        
        # æ£€æŸ¥æ˜¯å¦å®Œæˆ
        if len(self.tour) == self.num_nodes:
            # å›åˆ°èµ·å§‹èŠ‚ç‚¹ï¼ˆç¡®ä¿åœ¨æ­£ç¡®çš„è®¾å¤‡ä¸Šï¼‰
            final_distance = self.calculate_distance(self.current_node, torch.zeros_like(self.current_node))
            self.tour_length += final_distance
            self.done = torch.ones_like(self.done)
            
            # è®¡ç®—å¥–åŠ±ï¼ˆè´Ÿçš„è·¯å¾„é•¿åº¦ï¼‰
            reward = -self.tour_length
        else:
            # ç¡®ä¿rewardåœ¨æ­£ç¡®çš„è®¾å¤‡ä¸Š
            reward = torch.zeros(self.batch_size, self.pomo_size, device=self.points.device)
        
        return self.get_state(), reward, self.done
    
    def get_state(self):
        """è·å–å½“å‰çŠ¶æ€"""
        return {
            'current_node': self.current_node,
            'visited_mask': self.visited_mask,
            'adj_matrix': self.adj_matrix,
            'points': self.points,
            'tour_length': self.tour_length,
            'done': self.done
        }
    
    def calculate_distance(self, node1, node2):
        """è®¡ç®—ä¸¤ä¸ªèŠ‚ç‚¹ä¹‹é—´çš„æ¬§å‡ é‡Œå¾—è·ç¦»"""
        # node1, node2: (batch_size, pomo_size)
        batch_size, pomo_size = node1.shape
        
        # è·å–èŠ‚ç‚¹åæ ‡
        node1_coords = self.points[self.BATCH_IDX, node1]  # (batch_size, pomo_size, 2)
        node2_coords = self.points[self.BATCH_IDX, node2]  # (batch_size, pomo_size, 2)
        
        # è®¡ç®—æ¬§å‡ é‡Œå¾—è·ç¦»
        distance = torch.sqrt(((node1_coords - node2_coords) ** 2).sum(dim=-1))
        return distance
    
    def get_available_actions_mask(self):
        """è·å–å¯ç”¨åŠ¨ä½œçš„æ©ç """
        # è¿”å›æœªè®¿é—®èŠ‚ç‚¹çš„æ©ç 
        return ~self.visited_mask


class TSPRLModel(nn.Module):
    """åŸºäºé‚»æ¥çŸ©é˜µçš„TSPå¼ºåŒ–å­¦ä¹ æ¨¡å‹ï¼ˆå¯é€‰ç®€å•ç¥ç»ç½‘ç»œå¢å¼ºï¼‰"""
    
    def __init__(self, 
                 use_neural_network=True,
                 network_type='linear',  # 'linear', 'mlp', 'none'
                 embedding_dim=64,
                 hidden_dim=128):
        super().__init__()
        
        self.use_neural_network = use_neural_network
        self.network_type = network_type
        self.embedding_dim = embedding_dim
        
        if self.use_neural_network and self.network_type != 'none':
            if self.network_type == 'linear':
                # ç®€å•çº¿æ€§å±‚ï¼šèŠ‚ç‚¹åæ ‡ -> åµŒå…¥
                self.node_embedding = nn.Linear(2, embedding_dim)
                self.context_projection = nn.Linear(embedding_dim, 1)
                
            elif self.network_type == 'mlp':
                # ç®€å•MLPï¼šèŠ‚ç‚¹åæ ‡ -> éšè—å±‚ -> åµŒå…¥
                self.node_embedding = nn.Sequential(
                    nn.Linear(2, hidden_dim),
                    nn.ReLU(),
                    nn.Linear(hidden_dim, embedding_dim)
                )
                self.context_projection = nn.Sequential(
                    nn.Linear(embedding_dim, hidden_dim // 2),
                    nn.ReLU(),
                    nn.Linear(hidden_dim // 2, 1)
                )
        
        print(f"TSPRLModelåˆå§‹åŒ–: use_neural_network={use_neural_network}, network_type={network_type}")
        
    def forward(self, state):
        """
        å‰å‘ä¼ æ’­ - ä»¥é‚»æ¥çŸ©é˜µä¸ºä¸»è¦å†³ç­–ä¾æ®
        Args:
            state: ç¯å¢ƒçŠ¶æ€å­—å…¸
        Returns:
            logits: (batch_size, pomo_size, num_nodes) - åŠ¨ä½œæ¦‚ç‡logits
        """
        points = state['points']
        current_node = state['current_node']
        visited_mask = state['visited_mask']
        adj_matrix = state['adj_matrix']
        
        batch_size, pomo_size = current_node.shape
        num_nodes = points.shape[1]
        
        # åŠ¨æ€åˆ›å»ºæ‰¹æ¬¡å’ŒPOMOç´¢å¼•ï¼ˆç”¨äºé«˜çº§ç´¢å¼•ï¼‰
        BATCH_IDX = torch.arange(batch_size, device=current_node.device)[:, None].expand(batch_size, pomo_size)
        # POMO_IDX = torch.arange(pomo_size, device=current_node.device)[None, :].expand(batch_size, pomo_size)
        
        # ä¸»è¦å†³ç­–ä¾æ®ï¼šä»é‚»æ¥çŸ©é˜µè·å–æƒé‡
        # adj_matrix: (batch_size, num_nodes, num_nodes)
        # è·å–ä»å½“å‰èŠ‚ç‚¹åˆ°æ‰€æœ‰èŠ‚ç‚¹çš„è¿æ¥æƒé‡
        adj_logits = adj_matrix[BATCH_IDX, current_node]  # (batch_size, pomo_size, num_nodes)
        
        # å¯é€‰çš„ç¥ç»ç½‘ç»œå¢å¼º
        if self.use_neural_network and self.network_type != 'none':
            # è·å–èŠ‚ç‚¹ç‰¹å¾
            node_features = self.node_embedding(points)  # (batch_size, num_nodes, embedding_dim)
            
            # è·å–å½“å‰èŠ‚ç‚¹ç‰¹å¾
            current_features = node_features[BATCH_IDX, current_node]  # (batch_size, pomo_size, embedding_dim)
            
            # è®¡ç®—ä¸Šä¸‹æ–‡æƒé‡
            # context_weights = self.context_projection(current_features)  # (batch_size, pomo_size, 1)
            
            # è®¡ç®—æ‰€æœ‰èŠ‚ç‚¹çš„ç‰¹å¾åŒ¹é…åº¦
            # ä½¿ç”¨ç®€å•çš„ç‚¹ç§¯è®¡ç®—ç›¸ä¼¼åº¦
            node_features_expanded = node_features.unsqueeze(1).expand(batch_size, pomo_size, num_nodes, self.embedding_dim)
            current_features_expanded = current_features.unsqueeze(2).expand(batch_size, pomo_size, num_nodes, self.embedding_dim)
            
            # è®¡ç®—ç‰¹å¾ç›¸ä¼¼åº¦
            feature_similarity = (node_features_expanded * current_features_expanded).sum(dim=-1)  # (batch_size, pomo_size, num_nodes)
            
            # ç»“åˆé‚»æ¥çŸ©é˜µå’Œç‰¹å¾ç›¸ä¼¼åº¦
            # é‚»æ¥çŸ©é˜µæƒé‡æ›´å¤§ï¼ˆä¸»å¯¼ä½œç”¨ï¼‰
            alpha = 0.8  # é‚»æ¥çŸ©é˜µæƒé‡
            beta = 0.2   # ç‰¹å¾ç›¸ä¼¼åº¦æƒé‡
            
            logits = alpha * adj_logits + beta * feature_similarity
            
        else:
            # åªä½¿ç”¨é‚»æ¥çŸ©é˜µ
            logits = adj_logits
        
        # åº”ç”¨è®¿é—®æ©ç ï¼ˆå·²è®¿é—®çš„èŠ‚ç‚¹è®¾ç½®ä¸ºè´Ÿæ— ç©·ï¼‰- ä½¿ç”¨torch.whereé¿å…æ¢¯åº¦é—®é¢˜
        masked_logits = torch.where(visited_mask, 
                                  torch.full_like(logits, float('-inf')), 
                                  logits)
        
        return masked_logits


class DiffusionRLTrainer:
    """æ‰©æ•£æ¨¡å‹+å¼ºåŒ–å­¦ä¹ è®­ç»ƒå™¨"""
    
    def __init__(self, 
                 diffusion_model_path,
                 num_nodes=50,
                 batch_size=32,
                 pomo_size=50,
                 lr=1e-4,
                 device='cuda',
                 # æ–°å¢è¶…å‚æ•°
                 use_neural_network=True,
                 network_type='linear',  # 'linear', 'mlp', 'none'
                 embedding_dim=64,
                 timestamp=None):
        
        self.device = device
        self.num_nodes = num_nodes
        self.batch_size = batch_size
        self.pomo_size = pomo_size
        
        # åˆå§‹åŒ–æ‰©æ•£æ¨¡å‹
        self.diffusion_model = self.load_diffusion_model(diffusion_model_path)
        
        # åˆå§‹åŒ–å¼ºåŒ–å­¦ä¹ æ¨¡å‹ï¼ˆä»¥é‚»æ¥çŸ©é˜µä¸ºä¸»ï¼‰
        self.rl_model = TSPRLModel(
            use_neural_network=use_neural_network,
            network_type=network_type,
            embedding_dim=embedding_dim
        ).to(device)
        
        # åˆå§‹åŒ–ç¯å¢ƒ
        self.env = TSPEnv(batch_size, num_nodes, pomo_size)
        
        # åˆå§‹åŒ–ä¼˜åŒ–å™¨
        if use_neural_network and network_type != 'none':
            # å¦‚æœä½¿ç”¨ç¥ç»ç½‘ç»œï¼ŒåŒæ—¶ä¼˜åŒ–æ‰©æ•£æ¨¡å‹å’ŒRLæ¨¡å‹
            all_params = list(self.diffusion_model.parameters()) + list(self.rl_model.parameters())
        else:
            # å¦‚æœä¸ä½¿ç”¨ç¥ç»ç½‘ç»œï¼Œåªä¼˜åŒ–æ‰©æ•£æ¨¡å‹
            all_params = list(self.diffusion_model.parameters())
            
        self.optimizer = Optimizer(all_params, lr=lr)
        self.scheduler = Scheduler(self.optimizer, milestones=[100, 200], gamma=0.1)
        
        # æ—¥å¿—
        self.logger = getLogger(name='diffusion_rl_trainer')
        
        # TensorBoardè®¾ç½®
        if timestamp is None:   
            timestamp = time.strftime("%Y%m%d_%H%M%S")
        log_dir = f'runs/diffusion_rl_tsp_{timestamp}'
        self.writer = SummaryWriter(log_dir=log_dir)
        self.logger.info(f"TensorBoardæ—¥å¿—ä¿å­˜åˆ°: {log_dir}")
        self.logger.info("å¯åŠ¨TensorBoard: tensorboard --logdir=runs")
        
        # æ¨¡å‹ä¿å­˜ç›®å½•è®¾ç½®
        self.save_dir = f'saved_models/diffusion_rl_tsp_{timestamp}'
        os.makedirs(self.save_dir, exist_ok=True)
        self.logger.info(f"æ¨¡å‹ä¿å­˜ç›®å½•: {self.save_dir}")
        
        # è®­ç»ƒç»Ÿè®¡
        self.global_step = 0
        self.best_tour_length = float('inf')
        self.best_eval_length = float('inf')  # è·Ÿè¸ªæœ€ä½³è¯„ä¼°ç»“æœ
        self.recent_losses = deque(maxlen=100)  # ä¿å­˜æœ€è¿‘100ä¸ªæŸå¤±å€¼
        self.recent_tour_lengths = deque(maxlen=100)  # ä¿å­˜æœ€è¿‘100ä¸ªè·¯å¾„é•¿åº¦
        
    def load_diffusion_model(self, model_path):
        """åŠ è½½æ‰©æ•£æ¨¡å‹"""
        from difusco.difusion_tool import arg_parser, TSPModel_v2
        
        args = arg_parser()
        args.ckpt_path = model_path
        args.resume_weight_only = True
        
        model = TSPModel_v2.load_from_checkpoint(args.ckpt_path, param_args=args)
        model = model.to(self.device)
        model.eval()
        
        # æ·»åŠ tensorç‰ˆæœ¬çš„ç”Ÿæˆæ–¹æ³•
        def generate_adj_tensor(points):
            """
            ç”Ÿæˆé‚»æ¥çŸ©é˜µçš„Tensorç‰ˆæœ¬ï¼Œä¿æŒæ¢¯åº¦è¿æ¥
            Args:
                points: (batch_size, num_nodes, 2) - èŠ‚ç‚¹åæ ‡
            Returns:
                adj_matrix: (batch_size, num_nodes, num_nodes) - é‚»æ¥çŸ©é˜µ
            """
            # ç¡®ä¿pointsåœ¨æ­£ç¡®è®¾å¤‡ä¸Š
            if isinstance(points, np.ndarray):
                points = torch.from_numpy(points).float().to(self.device)
            
            batch_size, num_nodes, _ = points.shape
            
            # åˆå§‹åŒ–éšæœºå™ªå£°çŸ©é˜µï¼ˆä¿æŒæ¢¯åº¦ï¼‰
            xt = torch.randn(batch_size, num_nodes, num_nodes, device=self.device, requires_grad=True)
            
            if model.diffusion_type == 'gaussian':
                xt.requires_grad_(True)
            else:
                xt = (xt > 0).long()
            
            steps = model.args.inference_diffusion_steps
            time_schedule = InferenceSchedule(
                inference_schedule=model.args.inference_schedule,
                T=model.diffusion.T, 
                inference_T=steps
            )
            
            # åˆ›å»ºä¸ä½¿ç”¨no_gradçš„å»å™ªæ­¥éª¤
            def gaussian_denoise_step_with_grad(points, xt, t, device, edge_index=None, target_t=None):
                """ä¿æŒæ¢¯åº¦çš„é«˜æ–¯å»å™ªæ­¥éª¤"""
                t_tensor = torch.from_numpy(t).view(1).to(device)
                epsilon_pred = model.forward(
                    points.float().to(device),
                    xt.float().to(device),
                    t_tensor.float().to(device),
                    edge_index.long().to(device) if edge_index is not None else None,
                )
                epsilon_pred = epsilon_pred.squeeze(1)
                xt = model.gaussian_posterior(target_t, t_tensor, epsilon_pred, xt)
                return xt
            
            def categorical_denoise_step_with_grad(points, xt, t, device, edge_index=None, target_t=None):
                """ä¿æŒæ¢¯åº¦çš„åˆ†ç±»å»å™ªæ­¥éª¤"""
                t_tensor = torch.from_numpy(t).view(1).to(device)
                x0_pred = model.forward(
                    points.float().to(device),
                    xt.float().to(device),
                    t_tensor.float().to(device),
                    edge_index.long().to(device) if edge_index is not None else None,
                )
                
                if not model.sparse:
                    x0_pred_prob = x0_pred.permute((0, 2, 3, 1)).contiguous().softmax(dim=-1)
                else:
                    x0_pred_prob = x0_pred.reshape((1, points.shape[0], -1, 2)).softmax(dim=-1)
                
                xt = model.categorical_posterior(target_t, t_tensor, x0_pred_prob, xt)
                return xt
            
            # æ‰©æ•£è¿­ä»£ï¼ˆä¸ä½¿ç”¨torch.no_grad()ï¼‰
            for i in range(steps):
                t1, t2 = time_schedule(i)
                t1 = np.array([t1]).astype(int)
                t2 = np.array([t2]).astype(int)
                
                if model.diffusion_type == 'gaussian':
                    xt = gaussian_denoise_step_with_grad(points, xt, t1, self.device, None, target_t=t2)
                else:
                    xt = categorical_denoise_step_with_grad(points, xt, t1, self.device, None, target_t=t2)
            
            # æœ€ç»ˆå¤„ç†ï¼ˆä¿æŒæ¢¯åº¦ï¼‰
            if model.diffusion_type == 'gaussian':
                adj_matrix = xt * 0.5 + 0.5
            else:
                adj_matrix = xt.float() + 1e-6
            
            return adj_matrix
        
        # å°†æ–¹æ³•ç»‘å®šåˆ°æ¨¡å‹
        model.generate_adj_tensor = generate_adj_tensor
        
        return model
    
    def generate_problems(self, batch_size):
        """ç”ŸæˆTSPé—®é¢˜å®ä¾‹"""
        # ç”Ÿæˆéšæœºç‚¹
        points = torch.rand(batch_size, self.num_nodes, 2, device=self.device)
        return points
    
    def train_one_batch(self):
        """è®­ç»ƒä¸€ä¸ªæ‰¹æ¬¡"""
        # ç”Ÿæˆé—®é¢˜å®ä¾‹
        points = self.generate_problems(self.batch_size)
        
        # ä½¿ç”¨æ‰©æ•£æ¨¡å‹ç”Ÿæˆé‚»æ¥çŸ©é˜µ - ä¿æŒæ¢¯åº¦è¿æ¥
        # ç§»é™¤torch.no_grad()ä»¥ç¡®ä¿æ¢¯åº¦èƒ½ä¼ æ’­åˆ°æ‰©æ•£æ¨¡å‹å‚æ•°
        adj_matrix = self.diffusion_model.generate_adj_tensor(points)  # ä½¿ç”¨tensorç‰ˆæœ¬
        
        # éªŒè¯æ¢¯åº¦è¿æ¥
        # print(f"adj_matrix.requires_grad: {adj_matrix.requires_grad}")
        
        # é‡ç½®ç¯å¢ƒ
        state = self.env.reset(points, adj_matrix)
        
        # æ”¶é›†è½¨è¿¹
        log_probs = []
        rewards = []
        
        # POMO rollout
        for step in range(self.num_nodes - 1):
            # è·å–åŠ¨ä½œæ¦‚ç‡ï¼ˆä¸»è¦åŸºäºé‚»æ¥çŸ©é˜µï¼‰
            # è¿™é‡Œadj_matrixé€šè¿‡rl_modelå‚ä¸è®¡ç®—ï¼Œå»ºç«‹æ¢¯åº¦è¿æ¥
            logits = self.rl_model(state)
            
            # éªŒè¯logitsçš„æ¢¯åº¦è¿æ¥
            # if step == 0:  # åªåœ¨ç¬¬ä¸€æ­¥æ‰“å°ï¼Œé¿å…è¿‡å¤šè¾“å‡º
            #     print(f"logits.requires_grad: {logits.requires_grad}")
            
            probs = F.softmax(logits, dim=-1)
            
            # é‡‡æ ·åŠ¨ä½œ
            action_dist = torch.distributions.Categorical(probs)
            actions = action_dist.sample()
            
            # è®°å½•logæ¦‚ç‡
            log_prob = action_dist.log_prob(actions)
            log_probs.append(log_prob)
            
            # æ‰§è¡ŒåŠ¨ä½œ
            state, reward, done = self.env.step(actions)
            
            if done.all():
                rewards.append(reward)
                break
        
        # è®¡ç®—æ€»å¥–åŠ±
        total_rewards = rewards[-1] if rewards else torch.zeros(self.batch_size, self.pomo_size, device=self.device)
        
        # è·å–æœ€ä½³è·¯å¾„ä¿¡æ¯ç”¨äºå¯è§†åŒ–
        best_tour_info = self.get_best_tour_info(points, adj_matrix, total_rewards)
        
        # è®¡ç®—advantage
        baseline = total_rewards.mean(dim=1, keepdim=True)
        advantage = total_rewards - baseline
        
        # è®¡ç®—æ€»logæ¦‚ç‡
        total_log_prob = torch.stack(log_probs).sum(dim=0)
        
        # è®¡ç®—REINFORCEæŸå¤±
        # ç°åœ¨è¿™ä¸ªæŸå¤±åŒ…å«äº†ä»æ‰©æ•£æ¨¡å‹å‚æ•°åˆ°adj_matrixåˆ°rewardçš„å®Œæ•´è®¡ç®—å›¾
        rl_loss = -(advantage * total_log_prob).mean()
        
        # éªŒè¯æŸå¤±çš„æ¢¯åº¦è¿æ¥
        # print(f"rl_loss.requires_grad: {rl_loss.requires_grad}")
        
        # åå‘ä¼ æ’­ - ç°åœ¨æ¢¯åº¦å¯ä»¥æ­£ç¡®ä¼ æ’­åˆ°æ‰©æ•£æ¨¡å‹å‚æ•°
        self.optimizer.zero_grad()
        rl_loss.backward()
        
        # è®°å½•æ¢¯åº¦ä¿¡æ¯
        diffusion_grad_norm = 0.0
        rl_grad_norm = 0.0
        
        # è®¡ç®—æ‰©æ•£æ¨¡å‹æ¢¯åº¦èŒƒæ•°
        for p in self.diffusion_model.parameters():
            if p.grad is not None:
                diffusion_grad_norm += p.grad.data.norm(2).item() ** 2
        diffusion_grad_norm = diffusion_grad_norm ** 0.5
        
        # è®¡ç®—RLæ¨¡å‹æ¢¯åº¦èŒƒæ•°
        for p in self.rl_model.parameters():
            if p.grad is not None:
                rl_grad_norm += p.grad.data.norm(2).item() ** 2
        rl_grad_norm = rl_grad_norm ** 0.5
        
        # éªŒè¯æ‰©æ•£æ¨¡å‹å‚æ•°æ˜¯å¦æœ‰æ¢¯åº¦
        # has_diffusion_grad = any(p.grad is not None for p in self.diffusion_model.parameters())
        # print(f"æ‰©æ•£æ¨¡å‹å‚æ•°æœ‰æ¢¯åº¦: {has_diffusion_grad}")
        
        self.optimizer.step()
        
        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        best_rewards = total_rewards.max(dim=1)[0]
        avg_reward = best_rewards.mean().item()
        avg_tour_length = -avg_reward
        
        # è®°å½•åˆ°TensorBoard
        self.log_to_tensorboard(avg_tour_length, rl_loss.item(), diffusion_grad_norm, rl_grad_norm, 
                               total_rewards, adj_matrix, points, best_tour_info)
        
        # æ›´æ–°ç»Ÿè®¡
        self.recent_losses.append(rl_loss.item())
        self.recent_tour_lengths.append(avg_tour_length)
        self.global_step += 1
        
        return avg_tour_length, rl_loss.item()
    
    def get_best_tour_info(self, points, adj_matrix, total_rewards):
        """è·å–æœ€ä½³è·¯å¾„ä¿¡æ¯ç”¨äºå¯è§†åŒ–"""
        with torch.no_grad():
            # æ‰¾åˆ°ç¬¬ä¸€ä¸ªbatchä¸­æœ€ä½³çš„POMOå®ä¾‹
            batch_idx = 0
            best_pomo_idx = total_rewards[batch_idx].argmax().item()
            
            # é‡æ–°è¿è¡Œæ¨ç†è·å–æœ€ä½³è·¯å¾„ï¼ˆè´ªå¿ƒè§£ç ï¼‰
            self.rl_model.eval()
            
            # åˆ›å»ºå•ä¸ªå®ä¾‹çš„ç¯å¢ƒæ¥è·å–å®Œæ•´è·¯å¾„
            single_points = points[batch_idx:batch_idx+1]  # (1, num_nodes, 2)
            single_adj = adj_matrix[batch_idx:batch_idx+1]  # (1, num_nodes, num_nodes)
            
            # ä¸´æ—¶åˆ›å»ºå•POMOç¯å¢ƒ
            temp_env = TSPEnv(1, self.num_nodes, 1)
            state = temp_env.reset(single_points, single_adj)
            
            tour_nodes = [0]  # ä»èŠ‚ç‚¹0å¼€å§‹
            
            # è´ªå¿ƒè§£ç è·å–å®Œæ•´è·¯å¾„
            for step in range(self.num_nodes - 1):
                logits = self.rl_model(state)
                action = logits.argmax(dim=-1)
                tour_nodes.append(action.item())
                state, _, done = temp_env.step(action)
                
                if done.all():
                    break
            
            # å›åˆ°èµ·å§‹ç‚¹å®Œæˆç¯è·¯
            tour_nodes.append(0)
            
            self.rl_model.train()
            
            return {
                'tour_nodes': tour_nodes,
                'points': single_points[0].cpu().numpy(),
                'best_reward': total_rewards[batch_idx, best_pomo_idx].item()
            }
    
    def log_to_tensorboard(self, avg_tour_length, loss, diff_grad_norm, rl_grad_norm, 
                          total_rewards, adj_matrix, points, best_tour_info):
        """è®°å½•è®­ç»ƒæ•°æ®åˆ°TensorBoard"""
        
        # åŸºæœ¬è®­ç»ƒæŒ‡æ ‡
        self.writer.add_scalar('Training/Average_Tour_Length', avg_tour_length, self.global_step)
        self.writer.add_scalar('Training/Loss', loss, self.global_step)
        self.writer.add_scalar('Training/Learning_Rate', self.optimizer.param_groups[0]['lr'], self.global_step)
        
        # æ¢¯åº¦ä¿¡æ¯
        self.writer.add_scalar('Gradients/Diffusion_Model_Grad_Norm', diff_grad_norm, self.global_step)
        self.writer.add_scalar('Gradients/RL_Model_Grad_Norm', rl_grad_norm, self.global_step)
        
        # å¥–åŠ±åˆ†å¸ƒç»Ÿè®¡
        best_rewards = total_rewards.max(dim=1)[0]
        worst_rewards = total_rewards.min(dim=1)[0]
        mean_rewards = total_rewards.mean(dim=1)
        
        self.writer.add_scalar('Rewards/Best_Reward', best_rewards.mean().item(), self.global_step)
        self.writer.add_scalar('Rewards/Worst_Reward', worst_rewards.mean().item(), self.global_step)
        self.writer.add_scalar('Rewards/Mean_Reward', mean_rewards.mean().item(), self.global_step)
        self.writer.add_scalar('Rewards/Reward_Std', total_rewards.std().item(), self.global_step)
        
        # æ›´æ–°æœ€ä½³è®°å½•
        if avg_tour_length < self.best_tour_length:
            self.best_tour_length = avg_tour_length
            self.writer.add_scalar('Training/Best_Tour_Length', self.best_tour_length, self.global_step)
        
        # é‚»æ¥çŸ©é˜µç»Ÿè®¡
        adj_mean = adj_matrix.mean().item()
        adj_std = adj_matrix.std().item()
        adj_max = adj_matrix.max().item()
        adj_min = adj_matrix.min().item()
        
        self.writer.add_scalar('Adjacency_Matrix/Mean', adj_mean, self.global_step)
        self.writer.add_scalar('Adjacency_Matrix/Std', adj_std, self.global_step)
        self.writer.add_scalar('Adjacency_Matrix/Max', adj_max, self.global_step)
        self.writer.add_scalar('Adjacency_Matrix/Min', adj_min, self.global_step)
        
        # ç§»åŠ¨å¹³å‡
        if len(self.recent_losses) > 10:
            self.writer.add_scalar('Training/Loss_MA', np.mean(list(self.recent_losses)), self.global_step)
            self.writer.add_scalar('Training/Tour_Length_MA', np.mean(list(self.recent_tour_lengths)), self.global_step)
        
        # æ¯100æ­¥å¯è§†åŒ–ä¸€ä¸ªTSPå®ä¾‹
        if self.global_step % 100 == 0:
            self.visualize_tsp_solution(points[0], adj_matrix[0], total_rewards[0], best_tour_info)
    
    def visualize_tsp_solution(self, points, adj_matrix, rewards, best_tour_info):
        """å¯è§†åŒ–TSPè§£å†³æ–¹æ¡ˆ"""
        try:
            import matplotlib.pyplot as plt
            import matplotlib.patches as patches
            
            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))
            
            # å·¦å›¾ï¼šèŠ‚ç‚¹åˆ†å¸ƒå’Œæœ€ä½³æ±‚è§£è·¯å¾„
            points_np = points.cpu().numpy()
            tour_nodes = best_tour_info['tour_nodes']
            best_reward = best_tour_info['best_reward']
            
            # ç»˜åˆ¶èŠ‚ç‚¹
            ax1.scatter(points_np[:, 0], points_np[:, 1], c='red', s=80, zorder=3)
            
            # æ ‡æ³¨èŠ‚ç‚¹ç¼–å·
            for i, (x, y) in enumerate(points_np):
                ax1.annotate(str(i), (x, y), xytext=(5, 5), textcoords='offset points', 
                           fontsize=8, fontweight='bold')
            
            # ç»˜åˆ¶TSPè·¯å¾„
            tour_coords = points_np[tour_nodes]
            
            # ç»˜åˆ¶è·¯å¾„çº¿æ®µ
            for i in range(len(tour_nodes) - 1):
                start_point = tour_coords[i]
                end_point = tour_coords[i + 1]
                ax1.plot([start_point[0], end_point[0]], [start_point[1], end_point[1]], 
                        'b-', linewidth=2, alpha=0.7, zorder=2)
                
                # æ·»åŠ ç®­å¤´è¡¨ç¤ºæ–¹å‘
                dx = end_point[0] - start_point[0]
                dy = end_point[1] - start_point[1]
                ax1.arrow(start_point[0] + 0.7*dx, start_point[1] + 0.7*dy, 
                         0.1*dx, 0.1*dy, head_width=0.02, head_length=0.02, 
                         fc='blue', ec='blue', zorder=2)
            
            # é«˜äº®èµ·å§‹èŠ‚ç‚¹
            start_point = points_np[0]
            circle = plt.Circle((start_point[0], start_point[1]), 0.03, 
                              color='green', fill=True, zorder=4)
            ax1.add_patch(circle)
            ax1.annotate('START', (start_point[0], start_point[1]), 
                        xytext=(10, -15), textcoords='offset points',
                        fontsize=8, fontweight='bold', color='green')
            
            # è®¡ç®—è·¯å¾„é•¿åº¦
            path_length = -best_reward
            
            ax1.set_title(f'TSPèŠ‚ç‚¹åˆ†å¸ƒä¸æ±‚è§£è·¯å¾„\nè·¯å¾„é•¿åº¦: {path_length:.3f}')
            ax1.set_xlabel('Xåæ ‡')
            ax1.set_ylabel('Yåæ ‡')
            ax1.grid(True, alpha=0.3)
            ax1.set_aspect('equal')
            
            # æ·»åŠ è·¯å¾„é¡ºåºä¿¡æ¯
            path_str = ' â†’ '.join([str(node) for node in tour_nodes[:6]]) + '...'
            ax1.text(0.02, 0.98, f'è·¯å¾„: {path_str}', transform=ax1.transAxes, 
                    fontsize=8, verticalalignment='top',
                    bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))
            
            # å³å›¾ï¼šé‚»æ¥çŸ©é˜µçƒ­åŠ›å›¾
            adj_np = adj_matrix.cpu().detach().numpy()
            im = ax2.imshow(adj_np, cmap='viridis', interpolation='nearest')
            ax2.set_title('æ‰©æ•£æ¨¡å‹ç”Ÿæˆçš„é‚»æ¥çŸ©é˜µ')
            ax2.set_xlabel('ç›®æ ‡èŠ‚ç‚¹')
            ax2.set_ylabel('æºèŠ‚ç‚¹')
            
            # åœ¨é‚»æ¥çŸ©é˜µä¸Šæ ‡å‡ºå®é™…ä½¿ç”¨çš„è·¯å¾„
            for i in range(len(tour_nodes) - 1):
                from_node = tour_nodes[i]
                to_node = tour_nodes[i + 1]
                # åœ¨é‚»æ¥çŸ©é˜µä¸Šç”»çº¢è‰²æ–¹æ¡†æ ‡è®°å®é™…è·¯å¾„
                rect = patches.Rectangle((to_node-0.4, from_node-0.4), 0.8, 0.8, 
                                       linewidth=2, edgecolor='red', facecolor='none')
                ax2.add_patch(rect)
            
            plt.colorbar(im, ax=ax2)
            
            # æ·»åŠ æ€»ä½“ä¿¡æ¯
            best_reward_overall = rewards.max().item()
            fig.suptitle(f'æ­¥éª¤ {self.global_step} | æœ€ä½³å¥–åŠ±: {best_reward_overall:.3f} | å½“å‰å±•ç¤ºè·¯å¾„é•¿åº¦: {path_length:.3f}', 
                        fontsize=12)
            
            # plt.tight_layout()
            
            # ä¿å­˜åˆ°TensorBoard
            self.writer.add_figure('Visualization/TSP_Instance_with_Solution', fig, self.global_step)
            
            plt.close(fig)
            
        except Exception as e:
            self.logger.warning(f"å¯è§†åŒ–å¤±è´¥: {e}")
            import traceback
            self.logger.warning(f"é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
    
    def train(self, num_epochs=1000, log_interval=10):
        """è®­ç»ƒä¸»å¾ªç¯"""
        self.logger.info("å¼€å§‹è®­ç»ƒæ‰©æ•£æ¨¡å‹+å¼ºåŒ–å­¦ä¹ ...")
        self.logger.info(f"RLæ¨¡å‹é…ç½®: use_neural_network={self.rl_model.use_neural_network}, network_type={self.rl_model.network_type}")
        self.logger.info(f"TensorBoardæ—¥å¿—: {self.writer.log_dir}")
        
        # è®°å½•è¶…å‚æ•°
        self.writer.add_hparams({
            'num_nodes': self.num_nodes,
            'batch_size': self.batch_size,
            'pomo_size': self.pomo_size,
            'lr': self.optimizer.param_groups[0]['lr'],
            'use_neural_network': self.rl_model.use_neural_network,
            'network_type': self.rl_model.network_type,
        }, {})
        
        start_time = time.time()
        
        for epoch in range(num_epochs):
            epoch_start_time = time.time()
            
            # è®­ç»ƒæ¨¡å¼
            self.rl_model.train()
            self.diffusion_model.train()
            
            # è®­ç»ƒä¸€ä¸ªæ‰¹æ¬¡
            avg_length, total_loss = self.train_one_batch()
            
            # å­¦ä¹ ç‡è°ƒåº¦
            self.scheduler.step()
            
            # è®°å½•æ¯ä¸ªepochçš„æ—¶é—´
            epoch_time = time.time() - epoch_start_time
            self.writer.add_scalar('Training/Epoch_Time', epoch_time, epoch)
            
            # è®°å½•æ—¥å¿—
            if epoch % log_interval == 0:
                elapsed_time = time.time() - start_time
                self.logger.info(f"Epoch {epoch:4d}: "
                               f"å¹³å‡è·¯å¾„é•¿åº¦={avg_length:.4f}, "
                               f"æ€»æŸå¤±={total_loss:.4f}, "
                               f"æœ€ä½³é•¿åº¦={self.best_tour_length:.4f}, "
                               f"ç”¨æ—¶={elapsed_time:.1f}s")
                
                # è®°å½•è¿›åº¦ä¿¡æ¯
                self.writer.add_scalar('Training/Progress', epoch / num_epochs, epoch)
                self.writer.add_scalar('Training/Elapsed_Time', elapsed_time, epoch)
            
            # å®šæœŸè¯„ä¼°
            if epoch % 50 == 0 and epoch > 0:
                self.logger.info(f"è¿›è¡Œç¬¬{epoch}è½®è¯„ä¼°...")
                eval_length, is_best = self.evaluate(num_test_instances=100, visualize_solutions=True, max_visualizations=3)
                self.writer.add_scalar('Evaluation/Average_Tour_Length', eval_length, epoch)
                self.logger.info(f"è¯„ä¼°å®Œæˆï¼Œå¹³å‡è·¯å¾„é•¿åº¦: {eval_length:.4f}")
                
                # å¦‚æœæ˜¯æœ€ä½³ç»“æœï¼Œä¿å­˜æ¨¡å‹
                if is_best:
                    self.save_best_model(eval_length, epoch)
            
            # ä¿å­˜æ¨¡å‹
            if epoch % 100 == 0 and epoch > 0:
                self.save_checkpoint(epoch)
        
        # è®­ç»ƒç»“æŸ
        total_time = time.time() - start_time
        self.logger.info(f"è®­ç»ƒå®Œæˆï¼æ€»ç”¨æ—¶: {total_time:.1f}s")
        self.logger.info(f"æœ€ä½³è·¯å¾„é•¿åº¦: {self.best_tour_length:.4f}")
        
        # æœ€ç»ˆè¯„ä¼°
        final_eval_length, is_best_final = self.evaluate(num_test_instances=100, visualize_solutions=True, max_visualizations=5)
        self.writer.add_scalar('Final/Evaluation_Length', final_eval_length, num_epochs)
        
        # å¦‚æœæœ€ç»ˆè¯„ä¼°ä¹Ÿæ˜¯æœ€ä½³ç»“æœï¼Œä¿å­˜æ¨¡å‹
        if is_best_final:
            self.save_best_model(final_eval_length, num_epochs)
            self.logger.info("ğŸ‰ æœ€ç»ˆè¯„ä¼°äº§ç”Ÿäº†å†å²æœ€ä½³ç»“æœ!")
        
        # åˆ—å‡ºæ‰€æœ‰ä¿å­˜çš„æ¨¡å‹æ–‡ä»¶
        self.logger.info("=" * 50)
        self.list_saved_models()
        self.logger.info("=" * 50)
        
        # å…³é—­TensorBoard writer
        self.writer.close()
    
    def save_checkpoint(self, epoch):
        """ä¿å­˜æ£€æŸ¥ç‚¹"""
        checkpoint = {
            'epoch': epoch,
            'rl_model_state_dict': self.rl_model.state_dict(),
            'diffusion_model_state_dict': self.diffusion_model.state_dict(),
            'optimizer_state_dict': self.optimizer.state_dict(),
            'scheduler_state_dict': self.scheduler.state_dict(),
        }
        
        checkpoint_path = os.path.join(self.save_dir, f'checkpoint_epoch_{epoch}.pt')
        torch.save(checkpoint, checkpoint_path)
        self.logger.info(f"ä¿å­˜æ£€æŸ¥ç‚¹: {checkpoint_path}")
    
    def save_best_model(self, eval_length, epoch):
        """ä¿å­˜æœ€ä½³æ¨¡å‹å‚æ•°"""
        best_model = {
            'epoch': epoch,
            'eval_length': eval_length,
            'best_eval_length': self.best_eval_length,
            'rl_model_state_dict': self.rl_model.state_dict(),
            'diffusion_model_state_dict': self.diffusion_model.state_dict(),
            'optimizer_state_dict': self.optimizer.state_dict(),
            'scheduler_state_dict': self.scheduler.state_dict(),
            'global_step': self.global_step,
        }
        
        best_model_path = os.path.join(self.save_dir, 'best_model.pt')
        torch.save(best_model, best_model_path)
        self.logger.info(f"ğŸ¯ ä¿å­˜æœ€ä½³æ¨¡å‹: {best_model_path} (è¯„ä¼°é•¿åº¦: {eval_length:.4f})")
        
        # åŒæ—¶è®°å½•åˆ°TensorBoard
        self.writer.add_scalar('Best_Model/Eval_Length', eval_length, epoch)
        self.writer.add_scalar('Best_Model/Save_Epoch', epoch, epoch)
    
    def load_best_model(self, model_path=None):
        """åŠ è½½æœ€ä½³æ¨¡å‹å‚æ•°"""
        if model_path is None:
            model_path = os.path.join(self.save_dir, 'best_model.pt')
        
        try:
            checkpoint = torch.load(model_path, map_location=self.device)
            
            self.rl_model.load_state_dict(checkpoint['rl_model_state_dict'])
            self.diffusion_model.load_state_dict(checkpoint['diffusion_model_state_dict'])
            self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
            self.scheduler.load_state_dict(checkpoint['scheduler_state_dict'])
            
            self.best_eval_length = checkpoint['best_eval_length']
            self.global_step = checkpoint['global_step']
            
            self.logger.info(f"âœ… æˆåŠŸåŠ è½½æœ€ä½³æ¨¡å‹: {model_path}")
            self.logger.info(f"ğŸ“Š æ¨¡å‹è¯„ä¼°é•¿åº¦: {checkpoint['eval_length']:.4f}")
            self.logger.info(f"ğŸ¯ è®­ç»ƒè½®æ¬¡: {checkpoint['epoch']}")
            
            return True
            
        except FileNotFoundError:
            self.logger.warning(f"âŒ æœªæ‰¾åˆ°æœ€ä½³æ¨¡å‹æ–‡ä»¶: {model_path}")
            return False
        except Exception as e:
            self.logger.error(f"âŒ åŠ è½½æœ€ä½³æ¨¡å‹å¤±è´¥: {e}")
            return False
    
    def evaluate(self, num_test_instances=100, visualize_solutions=True, max_visualizations=5):
        """è¯„ä¼°æ¨¡å‹æ€§èƒ½"""
        self.rl_model.eval()
        self.diffusion_model.eval()
        
        total_lengths = []
        eval_start_time = time.time()
        
        # å­˜å‚¨è§£å†³æ–¹æ¡ˆç”¨äºå¯è§†åŒ–
        solutions_to_visualize = []
        
        with torch.no_grad():
            for batch_idx in range(num_test_instances // self.batch_size):
                # ç”Ÿæˆæµ‹è¯•é—®é¢˜
                points = self.generate_problems(self.batch_size)
                
                # ç”Ÿæˆé‚»æ¥çŸ©é˜µï¼ˆè¯„ä¼°æ—¶ä½¿ç”¨åŸå§‹æ–¹æ³•ï¼Œä¸éœ€è¦æ¢¯åº¦ï¼‰
                adj_matrix_np = self.diffusion_model.generate_adj(points.cpu().numpy())
                adj_matrix = torch.from_numpy(adj_matrix_np).float().to(self.device)
                
                # é‡ç½®ç¯å¢ƒ
                state = self.env.reset(points, adj_matrix)
                
                # è®°å½•åˆå§‹çŠ¶æ€ç”¨äºè·¯å¾„è¿½è¸ª
                batch_tours = [[] for _ in range(self.batch_size)]
                for b in range(self.batch_size):
                    batch_tours[b].append(0)  # èµ·å§‹èŠ‚ç‚¹
                
                # è´ªå¿ƒè§£ç 
                for step in range(self.num_nodes - 1):
                    logits = self.rl_model(state)
                    actions = logits.argmax(dim=-1)
                    
                    # è®°å½•æ¯ä¸ªbatchçš„è·¯å¾„
                    for b in range(self.batch_size):
                        # å–ç¬¬ä¸€ä¸ªPOMOå®ä¾‹çš„è¡ŒåŠ¨ï¼ˆè´ªå¿ƒæœ€ä½³ï¼‰
                        batch_tours[b].append(actions[b, 0].item())
                    
                    state, reward, done = self.env.step(actions)
                    
                    if done.all():
                        break
                
                # å®Œæˆç¯è·¯
                for b in range(self.batch_size):
                    batch_tours[b].append(0)  # å›åˆ°èµ·å§‹èŠ‚ç‚¹
                
                # æ”¶é›†æœ€ä¼˜è·¯å¾„é•¿åº¦
                best_lengths = state['tour_length'].max(dim=1)[0]
                total_lengths.extend(best_lengths.cpu().numpy())
                
                # ä¿å­˜ä¸€äº›è§£å†³æ–¹æ¡ˆç”¨äºå¯è§†åŒ–
                if visualize_solutions and len(solutions_to_visualize) < max_visualizations:
                    for b in range(min(self.batch_size, max_visualizations - len(solutions_to_visualize))):
                        # è®¡ç®—è¿™ä¸ªbatchä¸­æœ€ä½³POMOå®ä¾‹çš„å¥–åŠ±
                        best_pomo_idx = state['tour_length'][b].argmax().item()
                        best_reward = -state['tour_length'][b, best_pomo_idx].item()
                        
                        solution_info = {
                            'points': points[b].cpu().numpy(),
                            'adj_matrix': adj_matrix[b].cpu().numpy(),
                            'tour_nodes': batch_tours[b],
                            'tour_length': -best_reward,
                            'batch_idx': batch_idx,
                            'instance_idx': b,
                            'rewards': state['tour_length'][b].cpu().numpy()  # æ‰€æœ‰POMOå®ä¾‹çš„é•¿åº¦
                        }
                        solutions_to_visualize.append(solution_info)
        
        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        avg_length = np.mean(total_lengths)
        std_length = np.std(total_lengths)
        min_length = np.min(total_lengths)
        max_length = np.max(total_lengths)
        
        eval_time = time.time() - eval_start_time
        
        # æ£€æŸ¥æ˜¯å¦ä¸ºæœ€ä½³ç»“æœ
        is_best = avg_length < self.best_eval_length
        if is_best:
            self.best_eval_length = avg_length
            self.logger.info(f"ğŸ† å‘ç°æ–°çš„æœ€ä½³è¯„ä¼°ç»“æœ! å¹³å‡è·¯å¾„é•¿åº¦: {avg_length:.4f}")
        
        # å¯è§†åŒ–è§£å†³æ–¹æ¡ˆ
        if visualize_solutions and solutions_to_visualize:
            self.logger.info(f"ğŸ¨ æ­£åœ¨å¯è§†åŒ– {len(solutions_to_visualize)} ä¸ªè¯„ä¼°è§£å†³æ–¹æ¡ˆ...")
            self.visualize_evaluation_solutions(solutions_to_visualize, avg_length, is_best)
        
        # è®°å½•åˆ°TensorBoard
        if hasattr(self, 'writer'):
            self.writer.add_scalar('Evaluation/Average_Length', avg_length, self.global_step)
            self.writer.add_scalar('Evaluation/Std_Length', std_length, self.global_step)
            self.writer.add_scalar('Evaluation/Min_Length', min_length, self.global_step)
            self.writer.add_scalar('Evaluation/Max_Length', max_length, self.global_step)
            self.writer.add_scalar('Evaluation/Time', eval_time, self.global_step)
            self.writer.add_scalar('Evaluation/Best_Ever_Length', self.best_eval_length, self.global_step)
            
            # æ·»åŠ é•¿åº¦åˆ†å¸ƒç›´æ–¹å›¾
            self.writer.add_histogram('Evaluation/Length_Distribution', np.array(total_lengths), self.global_step)
        
        self.logger.info(f"è¯„ä¼°ç»“æœ - å¹³å‡è·¯å¾„é•¿åº¦: {avg_length:.4f} Â± {std_length:.4f}")
        self.logger.info(f"è¯„ä¼°ç»“æœ - èŒƒå›´: [{min_length:.4f}, {max_length:.4f}]")
        self.logger.info(f"è¯„ä¼°ç»“æœ - å†å²æœ€ä½³: {self.best_eval_length:.4f}")
        
        return avg_length, is_best
    
    def visualize_evaluation_solutions(self, solutions, avg_length, is_best):
        """å¯è§†åŒ–è¯„ä¼°è¿‡ç¨‹ä¸­çš„è§£å†³æ–¹æ¡ˆ"""
        try:
            import matplotlib.pyplot as plt
            
            # æ‰¾åˆ°æœ€ä½³å’Œæœ€å·®çš„è§£å†³æ–¹æ¡ˆ
            best_solution = min(solutions, key=lambda x: x['tour_length'])
            worst_solution = max(solutions, key=lambda x: x['tour_length'])
            
            # åˆ›å»ºå¤šå­å›¾å±•ç¤º
            n_solutions = min(len(solutions), 4)  # æœ€å¤šæ˜¾ç¤º4ä¸ªè§£å†³æ–¹æ¡ˆ
            fig, axes = plt.subplots(2, 2, figsize=(16, 12))
            axes = axes.flatten()
            
            solutions_to_show = [best_solution, worst_solution] + solutions[:2] if len(solutions) > 2 else solutions
            
            for i, solution in enumerate(solutions_to_show[:n_solutions]):
                ax = axes[i]
                
                # å¤ç”¨ç°æœ‰çš„å¯è§†åŒ–é€»è¾‘
                points_np = solution['points']
                tour_nodes = solution['tour_nodes']
                adj_matrix_np = solution['adj_matrix']
                tour_length = solution['tour_length']
                
                # ç»˜åˆ¶èŠ‚ç‚¹
                ax.scatter(points_np[:, 0], points_np[:, 1], c='red', s=60, zorder=3)
                
                # æ ‡æ³¨èŠ‚ç‚¹ç¼–å·
                for j, (x, y) in enumerate(points_np):
                    ax.annotate(str(j), (x, y), xytext=(3, 3), textcoords='offset points', 
                              fontsize=7, fontweight='bold')
                
                # ç»˜åˆ¶TSPè·¯å¾„
                tour_coords = points_np[tour_nodes]
                
                # ç»˜åˆ¶è·¯å¾„çº¿æ®µ
                for j in range(len(tour_nodes) - 1):
                    start_point = tour_coords[j]
                    end_point = tour_coords[j + 1]
                    ax.plot([start_point[0], end_point[0]], [start_point[1], end_point[1]], 
                           'b-', linewidth=1.5, alpha=0.7, zorder=2)
                
                # é«˜äº®èµ·å§‹èŠ‚ç‚¹
                start_point = points_np[0]
                circle = plt.Circle((start_point[0], start_point[1]), 0.025, 
                                  color='green', fill=True, zorder=4)
                ax.add_patch(circle)
                
                # è®¾ç½®æ ‡é¢˜å’Œæ ‡ç­¾
                if i == 0 and solution == best_solution:
                    title_prefix = "ğŸ† æœ€ä½³è§£"
                elif i == 1 and solution == worst_solution:
                    title_prefix = "ğŸ“‰ æœ€å·®è§£"
                else:
                    title_prefix = f"è§£å†³æ–¹æ¡ˆ #{i+1}"
                    
                ax.set_title(f'{title_prefix}\né•¿åº¦: {tour_length:.3f}', fontsize=10)
                ax.set_xlabel('Xåæ ‡', fontsize=8)
                ax.set_ylabel('Yåæ ‡', fontsize=8)
                ax.grid(True, alpha=0.3)
                ax.set_aspect('equal')
            
            # éšè—æœªä½¿ç”¨çš„å­å›¾
            for i in range(n_solutions, 4):
                axes[i].set_visible(False)
            
            # è®¾ç½®æ€»æ ‡é¢˜
            best_indicator = " ğŸ† æ–°æœ€ä½³!" if is_best else ""
            fig.suptitle(f'è¯„ä¼°è§£å†³æ–¹æ¡ˆå¯è§†åŒ–{best_indicator}\nå¹³å‡é•¿åº¦: {avg_length:.4f} | æ­¥éª¤: {self.global_step}', 
                        fontsize=14, fontweight='bold')
            
            plt.tight_layout()
            
            # ä¿å­˜åˆ°TensorBoard
            if hasattr(self, 'writer'):
                self.writer.add_figure('Evaluation/Solutions_Visualization', fig, self.global_step)
            
            plt.close(fig)
            
        except Exception as e:
            self.logger.warning(f"è¯„ä¼°å¯è§†åŒ–å¤±è´¥: {e}")
            import traceback
            self.logger.warning(f"é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
    
    def list_saved_models(self):
        """åˆ—å‡ºä¿å­˜ç›®å½•ä¸­çš„æ‰€æœ‰æ¨¡å‹æ–‡ä»¶"""
        if not os.path.exists(self.save_dir):
            self.logger.info(f"ğŸ“ ä¿å­˜ç›®å½•ä¸å­˜åœ¨: {self.save_dir}")
            return []
        
        model_files = []
        for file in os.listdir(self.save_dir):
            if file.endswith('.pt'):
                file_path = os.path.join(self.save_dir, file)
                file_size = os.path.getsize(file_path) / (1024 * 1024)  # MB
                model_files.append({
                    'filename': file,
                    'filepath': file_path,
                    'size_mb': file_size,
                    'modified_time': time.ctime(os.path.getmtime(file_path))
                })
        
        if model_files:
            self.logger.info(f"ğŸ“ ä¿å­˜ç›®å½•: {self.save_dir}")
            self.logger.info("ğŸ’¾ å·²ä¿å­˜çš„æ¨¡å‹æ–‡ä»¶:")
            for model in sorted(model_files, key=lambda x: x['filename']):
                self.logger.info(f"  - {model['filename']} ({model['size_mb']:.1f}MB, {model['modified_time']})")
        else:
            self.logger.info(f"ğŸ“ ä¿å­˜ç›®å½•ä¸ºç©º: {self.save_dir}")
        
        return model_files


def create_logger():
    """åˆ›å»ºæ—¥å¿—å™¨"""
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )


def main(train_mode=False, test_mode=False, timestamp=None):
    """ä¸»å‡½æ•°"""
    # åˆ›å»ºæ—¥å¿—å™¨
    create_logger()
    
    # è®­ç»ƒå‚æ•°
    diffusion_model_path = 'tb_logs/tsp_diffusion/version_0/checkpoints/last.ckpt'
    
    # å¯é€‰é…ç½®ï¼šæ§åˆ¶æ˜¯å¦ä½¿ç”¨é¢å¤–çš„ç¥ç»ç½‘ç»œ
    # network_typeé€‰é¡¹ï¼š'linear', 'mlp', 'none'
    use_neural_network = False
    network_type = 'none'  # å¯ä»¥æ”¹ä¸º 'mlp', 'none' æ¥æµ‹è¯•ä¸åŒé…ç½®
    
    print(f"é…ç½®: use_neural_network={use_neural_network}, network_type={network_type}")
    print("ç½‘ç»œç±»å‹è¯´æ˜:")
    print("  - 'linear': ç®€å•çº¿æ€§å±‚å¢å¼º")
    print("  - 'mlp': å¤šå±‚æ„ŸçŸ¥æœºå¢å¼º") 
    print("  - 'none': çº¯é‚»æ¥çŸ©é˜µå†³ç­–")
    
    # åˆ›å»ºè®­ç»ƒå™¨
    trainer = DiffusionRLTrainer(
        diffusion_model_path=diffusion_model_path,
        num_nodes=50,
        batch_size=32,
        pomo_size=50,
        lr=1e-4,
        device='cuda' if torch.cuda.is_available() else 'cpu',
        # æ–°å¢å‚æ•°
        use_neural_network=use_neural_network,
        network_type=network_type,
        embedding_dim=64,
        timestamp=timestamp
    )
    
    if train_mode:
        # å¼€å§‹è®­ç»ƒ
        trainer.train(num_epochs=1000, log_interval=10)
    
    if test_mode:
        # è¯„ä¼°  
        print("\n" + "="*60)
        print("ğŸ”„ æ¼”ç¤ºæ¨¡å‹åŠ è½½åŠŸèƒ½:")
        
        # åˆ—å‡ºä¿å­˜çš„æ¨¡å‹
        saved_models = trainer.list_saved_models()
        
        # åŠ è½½æœ€ä½³æ¨¡å‹è¿›è¡Œæœ€ç»ˆæµ‹è¯•
        if trainer.load_best_model():
            print("âœ… æˆåŠŸåŠ è½½æœ€ä½³æ¨¡å‹ï¼Œè¿›è¡Œæœ€ç»ˆæµ‹è¯•...")
            test_length, _ = trainer.evaluate(num_test_instances=200, visualize_solutions=True, max_visualizations=8)
            print(f"ğŸ¯ ä½¿ç”¨æœ€ä½³æ¨¡å‹çš„æµ‹è¯•ç»“æœ: {test_length:.4f}")
        
        print("="*60)


if __name__ == "__main__":
    # timestamp = time.strftime("%Y%m%d_%H%M%S")
    # timestamp = '20250606_224244'
    timestamp = None
    main(train_mode=True, test_mode=True, timestamp=timestamp) 