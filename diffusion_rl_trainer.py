"""
æ‰©æ•£æ¨¡å‹ + å¼ºåŒ–å­¦ä¹ çš„TSPè®­ç»ƒå™¨
ç»“åˆdifuscoæ‰©æ•£æ¨¡å‹å’ŒPOMOå¼ºåŒ–å­¦ä¹ æ–¹æ³•
"""

import sys
import os
import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
from logging import getLogger
import logging
from torch.optim import Adam as Optimizer
from torch.optim.lr_scheduler import MultiStepLR as Scheduler
import time

# å¯¼å…¥æ‰©æ•£æ¨¡å‹ç›¸å…³
sys.path.append('/root/code/difusco_o/difusco_o/DIFUSCO/difusco')
from difusco.utils.diffusion_schedulers import InferenceSchedule

# å¯¼å…¥å¼ºåŒ–å­¦ä¹ ç›¸å…³
sys.path.append('/root/code/diffusco_o/difusco_o/DIFUSCO/mtnco/MTPOMO/POMO')
from mtnco.utils.utils import *


class TSPEnv:
    """TSPç¯å¢ƒï¼ŒåŸºäºæ‰©æ•£æ¨¡å‹ç”Ÿæˆçš„é‚»æ¥çŸ©é˜µè¿›è¡Œå¼ºåŒ–å­¦ä¹ """
    
    def __init__(self, batch_size, num_nodes, pomo_size=None):
        self.batch_size = batch_size
        self.num_nodes = num_nodes
        self.pomo_size = pomo_size if pomo_size else num_nodes
        
        # çŠ¶æ€å˜é‡
        self.points = None
        self.adj_matrix = None
        self.visited_mask = None
        self.current_node = None
        self.tour = None
        self.tour_length = None
        self.done = None
        
        # æ‰¹æ¬¡å’ŒPOMOç´¢å¼•
        self.BATCH_IDX = torch.arange(self.batch_size)[:, None].expand(self.batch_size, self.pomo_size)
        self.POMO_IDX = torch.arange(self.pomo_size)[None, :].expand(self.batch_size, self.pomo_size)
        
    def reset(self, points, adj_matrix):
        """é‡ç½®ç¯å¢ƒçŠ¶æ€"""
        self.points = points
        self.adj_matrix = adj_matrix
        
        device = points.device
        
        # åˆå§‹åŒ–çŠ¶æ€
        self.visited_mask = torch.zeros(self.batch_size, self.pomo_size, self.num_nodes, dtype=torch.bool, device=device)
        self.current_node = torch.zeros(self.batch_size, self.pomo_size, dtype=torch.long, device=device)
        self.tour = [torch.zeros(self.batch_size, self.pomo_size, dtype=torch.long, device=device)]
        self.tour_length = torch.zeros(self.batch_size, self.pomo_size, device=device)
        self.done = torch.zeros(self.batch_size, self.pomo_size, dtype=torch.bool, device=device)
        
        # ç¡®ä¿ç´¢å¼•åœ¨æ­£ç¡®çš„è®¾å¤‡ä¸Š
        self.BATCH_IDX = torch.arange(self.batch_size, device=device)[:, None].expand(self.batch_size, self.pomo_size)
        self.POMO_IDX = torch.arange(self.pomo_size, device=device)[None, :].expand(self.batch_size, self.pomo_size)
        
        # æ ‡è®°èµ·å§‹èŠ‚ç‚¹ä¸ºå·²è®¿é—®
        new_visited_mask = self.visited_mask.clone()
        new_visited_mask[self.BATCH_IDX, self.POMO_IDX, self.current_node] = True
        self.visited_mask = new_visited_mask
        
        return self.get_state()
    
    def step(self, action):
        """æ‰§è¡ŒåŠ¨ä½œ"""
        # æ›´æ–°å½“å‰èŠ‚ç‚¹
        prev_node = self.current_node.clone()
        self.current_node = action
        
        # è®¡ç®—ç§»åŠ¨è·ç¦»ï¼ˆåŸºäºçœŸå®æ¬§å‡ é‡Œå¾—è·ç¦»ï¼‰
        step_distance = self.calculate_distance(prev_node, self.current_node)
        self.tour_length += step_distance
        
        # æ ‡è®°èŠ‚ç‚¹ä¸ºå·²è®¿é—®
        new_visited_mask = self.visited_mask.clone()
        new_visited_mask[self.BATCH_IDX, self.POMO_IDX, self.current_node] = True
        self.visited_mask = new_visited_mask
        
        # æ·»åŠ åˆ°è·¯å¾„
        self.tour.append(self.current_node.clone())
        
        # æ£€æŸ¥æ˜¯å¦å®Œæˆ
        if len(self.tour) == self.num_nodes:
            # å›åˆ°èµ·å§‹èŠ‚ç‚¹
            final_distance = self.calculate_distance(self.current_node, torch.zeros_like(self.current_node))
            self.tour_length += final_distance
            self.done = torch.ones_like(self.done)
            reward = -self.tour_length
        else:
            reward = torch.zeros(self.batch_size, self.pomo_size, device=self.points.device)
        
        return self.get_state(), reward, self.done
    
    def get_state(self):
        """è·å–å½“å‰çŠ¶æ€"""
        return {
            'current_node': self.current_node,
            'visited_mask': self.visited_mask,
            'adj_matrix': self.adj_matrix,
            'points': self.points,
            'tour_length': self.tour_length,
            'done': self.done
        }
    
    def calculate_distance(self, node1, node2):
        """è®¡ç®—ä¸¤ä¸ªèŠ‚ç‚¹ä¹‹é—´çš„æ¬§å‡ é‡Œå¾—è·ç¦»"""
        batch_size, pomo_size = node1.shape
        
        # è·å–èŠ‚ç‚¹åæ ‡
        node1_coords = self.points[self.BATCH_IDX, node1]
        node2_coords = self.points[self.BATCH_IDX, node2]
        
        # è®¡ç®—æ¬§å‡ é‡Œå¾—è·ç¦»
        distance = torch.sqrt(((node1_coords - node2_coords) ** 2).sum(dim=-1))
        return distance


class TSPRLModel(nn.Module):
    """åŸºäºé‚»æ¥çŸ©é˜µçš„TSPå¼ºåŒ–å­¦ä¹ æ¨¡å‹"""
    
    def __init__(self, embedding_dim=64, use_linear_enhancement=True):
        super().__init__()
        self.embedding_dim = embedding_dim
        self.use_linear_enhancement = use_linear_enhancement
        
        # å¯é€‰çš„çº¿æ€§å±‚å¢å¼º
        if self.use_linear_enhancement:
            self.node_embedding = nn.Linear(2, embedding_dim)
        
    def forward(self, state):
        """å‰å‘ä¼ æ’­ - ä»¥é‚»æ¥çŸ©é˜µä¸ºä¸»è¦å†³ç­–ä¾æ®"""
        points = state['points']
        current_node = state['current_node']
        visited_mask = state['visited_mask']
        adj_matrix = state['adj_matrix']
        
        batch_size, pomo_size = current_node.shape
        num_nodes = points.shape[1]
        
        # åŠ¨æ€åˆ›å»ºæ‰¹æ¬¡ç´¢å¼•
        BATCH_IDX = torch.arange(batch_size, device=current_node.device)[:, None].expand(batch_size, pomo_size)
        
        # ä¸»è¦å†³ç­–ä¾æ®ï¼šä»é‚»æ¥çŸ©é˜µè·å–æƒé‡
        adj_logits = adj_matrix[BATCH_IDX, current_node]
        
        if self.use_linear_enhancement:
            # çº¿æ€§å±‚å¢å¼ºæ¨¡å¼
            node_features = self.node_embedding(points)
            current_features = node_features[BATCH_IDX, current_node]
            
            # è®¡ç®—ç‰¹å¾ç›¸ä¼¼åº¦
            node_features_expanded = node_features.unsqueeze(1).expand(batch_size, pomo_size, num_nodes, self.embedding_dim)
            current_features_expanded = current_features.unsqueeze(2).expand(batch_size, pomo_size, num_nodes, self.embedding_dim)
            feature_similarity = (node_features_expanded * current_features_expanded).sum(dim=-1)
            
            # ç»“åˆé‚»æ¥çŸ©é˜µå’Œç‰¹å¾ç›¸ä¼¼åº¦
            alpha = 0.8  # é‚»æ¥çŸ©é˜µæƒé‡
            beta = 0.2   # ç‰¹å¾ç›¸ä¼¼åº¦æƒé‡
            logits = alpha * adj_logits + beta * feature_similarity
        else:
            # çº¯é‚»æ¥çŸ©é˜µæ¨¡å¼
            logits = adj_logits
        
        # åº”ç”¨è®¿é—®æ©ç 
        masked_logits = torch.where(visited_mask, 
                                  torch.full_like(logits, float('-inf')), 
                                  logits)
        
        return masked_logits


class DiffusionRLTrainer:
    """æ‰©æ•£æ¨¡å‹+å¼ºåŒ–å­¦ä¹ è®­ç»ƒå™¨"""
    
    def __init__(self, 
                 diffusion_model_path,
                 num_nodes=50,
                 batch_size=32,
                 pomo_size=50,
                 lr=1e-4,
                 device='cuda',
                 use_single_case=True,
                 use_linear_enhancement=True):
        
        self.device = device
        self.num_nodes = num_nodes
        self.batch_size = batch_size
        self.pomo_size = pomo_size
        self.use_single_case = use_single_case
        self.use_linear_enhancement = use_linear_enhancement
        
        # åˆå§‹åŒ–æ‰©æ•£æ¨¡å‹
        self.diffusion_model = self.load_diffusion_model(diffusion_model_path)
        
        # å¦‚æœä½¿ç”¨å•ä¸€æ¡ˆä¾‹ï¼Œä»æµ‹è¯•é›†ä¸­è·å–å›ºå®šæ¡ˆä¾‹
        if self.use_single_case:
            self.fixed_case = self.load_fixed_case()
            self.logger = getLogger(name='diffusion_rl_trainer')
            self.logger.info("ä½¿ç”¨å•ä¸€æ¡ˆä¾‹è®­ç»ƒæ¨¡å¼")
            self.logger.info(f"å›ºå®šæ¡ˆä¾‹èŠ‚ç‚¹æ•°: {self.fixed_case['points'].shape[0]}")
            self.logger.info(f"å›ºå®šæ¡ˆä¾‹æœ€ä¼˜é•¿åº¦: {self.fixed_case['gt_length']:.4f}")
        else:
            self.fixed_case = None
        
        # åˆå§‹åŒ–å¼ºåŒ–å­¦ä¹ æ¨¡å‹
        self.rl_model = TSPRLModel(embedding_dim=64, use_linear_enhancement=self.use_linear_enhancement).to(device)
        
        # æ—¥å¿—å¢å¼ºæ¨¡å¼ä¿¡æ¯
        if not hasattr(self, 'logger'):
            self.logger = getLogger(name='diffusion_rl_trainer')
        
        if self.use_linear_enhancement:
            self.logger.info("ä½¿ç”¨çº¿æ€§å±‚å¢å¼ºæ¨¡å¼")
        else:
            self.logger.info("ä½¿ç”¨çº¯é‚»æ¥çŸ©é˜µæ¨¡å¼")
        
        # åˆå§‹åŒ–ç¯å¢ƒ
        self.env = TSPEnv(batch_size, num_nodes, pomo_size)
        
        # åˆå§‹åŒ–ä¼˜åŒ–å™¨
        all_params = list(self.diffusion_model.parameters()) + list(self.rl_model.parameters())
        self.optimizer = Optimizer(all_params, lr=lr)
        self.scheduler = Scheduler(self.optimizer, milestones=[100, 200], gamma=0.1)
        
        # è®­ç»ƒç»Ÿè®¡
        self.global_step = 0
        self.best_tour_length = float('inf')
        self.best_eval_length = float('inf')
        
    def load_diffusion_model(self, model_path):
        """åŠ è½½æ‰©æ•£æ¨¡å‹"""
        from difusco.difusion_tool import arg_parser, TSPModel_v2
        
        args = arg_parser()
        args.ckpt_path = model_path
        args.resume_weight_only = True
        
        model = TSPModel_v2.load_from_checkpoint(args.ckpt_path, param_args=args)
        model = model.to(self.device)
        model.eval()
        
        # æ·»åŠ tensorç‰ˆæœ¬çš„ç”Ÿæˆæ–¹æ³•
        def generate_adj_tensor(points):
            """ç”Ÿæˆé‚»æ¥çŸ©é˜µçš„Tensorç‰ˆæœ¬ï¼Œä¿æŒæ¢¯åº¦è¿æ¥"""
            if isinstance(points, np.ndarray):
                points = torch.from_numpy(points).float().to(self.device)
            
            batch_size, num_nodes, _ = points.shape
            
            # åˆå§‹åŒ–éšæœºå™ªå£°çŸ©é˜µ
            xt = torch.randn(batch_size, num_nodes, num_nodes, device=self.device, requires_grad=True)
            
            if model.diffusion_type == 'gaussian':
                xt.requires_grad_(True)
            else:
                xt = (xt > 0).long()
            
            steps = model.args.inference_diffusion_steps
            time_schedule = InferenceSchedule(
                inference_schedule=model.args.inference_schedule,
                T=model.diffusion.T, 
                inference_T=steps
            )
            
            # æ‰©æ•£è¿­ä»£
            for i in range(steps):
                t1, t2 = time_schedule(i)
                t1 = np.array([t1]).astype(int)
                t2 = np.array([t2]).astype(int)
                
                t_tensor = torch.from_numpy(t1).view(1).to(self.device)
                
                if model.diffusion_type == 'gaussian':
                    epsilon_pred = model.forward(
                        points.float().to(self.device),
                        xt.float().to(self.device),
                        t_tensor.float().to(self.device),
                        None
                    )
                    epsilon_pred = epsilon_pred.squeeze(1)
                    xt = model.gaussian_posterior(t2, t_tensor, epsilon_pred, xt)
                else:
                    x0_pred = model.forward(
                        points.float().to(self.device),
                        xt.float().to(self.device),
                        t_tensor.float().to(self.device),
                        None
                    )
                    x0_pred_prob = x0_pred.permute((0, 2, 3, 1)).contiguous().softmax(dim=-1)
                    xt = model.categorical_posterior(t2, t_tensor, x0_pred_prob, xt)
            
            # æœ€ç»ˆå¤„ç†
            if model.diffusion_type == 'gaussian':
                adj_matrix = xt * 0.5 + 0.5
            else:
                adj_matrix = xt.float() + 1e-6
            
            return adj_matrix
        
        model.generate_adj_tensor = generate_adj_tensor
        return model
    
    def load_fixed_case(self):
        """ä»æµ‹è¯•æ•°æ®é›†ä¸­åŠ è½½ä¸€ä¸ªå›ºå®šæ¡ˆä¾‹"""
        # ä¸´æ—¶åŠ è½½æ¨¡å‹è·å–æµ‹è¯•æ•°æ®
        from difusco.difusion_tool import arg_parser, TSPModel_v2
        
        args = arg_parser()
        temp_model = TSPModel_v2(param_args=args)
        test_dataloader = temp_model.test_dataloader()
        
        # è·å–ç¬¬ä¸€ä¸ªæµ‹è¯•æ¡ˆä¾‹
        first_batch = next(iter(test_dataloader))
        
        # è§£ææ•°æ®
        if not temp_model.sparse:
            real_batch_idx, points, adj_matrix_gt, gt_tour = first_batch
            points = points[0]  # å–ç¬¬ä¸€ä¸ªå®ä¾‹
            gt_tour = gt_tour[0]
        else:
            real_batch_idx, graph_data, point_indicator, edge_indicator, gt_tour = first_batch
            points = graph_data.x.reshape((-1, self.num_nodes, 2))[0]
            gt_tour = gt_tour.reshape(-1, self.num_nodes)[0]
        
        # è®¡ç®—çœŸå®æœ€ä¼˜è§£çš„æˆæœ¬
        points_np = points.cpu().numpy()
        gt_tour_np = gt_tour.cpu().numpy()
        
        gt_cost = 0.0
        for i in range(len(gt_tour_np)):
            start_node = gt_tour_np[i]
            end_node = gt_tour_np[(i + 1) % len(gt_tour_np)]
            distance = np.sqrt(np.sum((points_np[start_node] - points_np[end_node]) ** 2))
            gt_cost += distance
        
        return {
            'points': points_np,
            'gt_tour': gt_tour_np,
            'gt_length': gt_cost
        }
    
    def generate_problems(self, batch_size):
        """ç”ŸæˆTSPé—®é¢˜å®ä¾‹"""
        if self.use_single_case and self.fixed_case is not None:
            # ä½¿ç”¨å›ºå®šæ¡ˆä¾‹ï¼Œå¤åˆ¶åˆ°æ•´ä¸ªbatch
            points = torch.from_numpy(self.fixed_case['points']).float().to(self.device)
            points = points.unsqueeze(0).repeat(batch_size, 1, 1)
            return points
        else:
            # åŸæ¥çš„éšæœºç”Ÿæˆé€»è¾‘
            points = torch.rand(batch_size, self.num_nodes, 2, device=self.device)
            return points
    
    def train_one_batch(self):
        """è®­ç»ƒä¸€ä¸ªæ‰¹æ¬¡"""
        # ç”Ÿæˆé—®é¢˜å®ä¾‹
        points = self.generate_problems(self.batch_size)
        
        # ä½¿ç”¨æ‰©æ•£æ¨¡å‹ç”Ÿæˆé‚»æ¥çŸ©é˜µ
        adj_matrix = self.diffusion_model.generate_adj_tensor(points)
        
        # é‡ç½®ç¯å¢ƒ
        state = self.env.reset(points, adj_matrix)
        
        # æ”¶é›†è½¨è¿¹
        log_probs = []
        rewards = []
        
        # POMO rollout
        for step in range(self.num_nodes - 1):
            logits = self.rl_model(state)
            probs = F.softmax(logits, dim=-1)
            
            # é‡‡æ ·åŠ¨ä½œ
            action_dist = torch.distributions.Categorical(probs)
            actions = action_dist.sample()
            
            # è®°å½•logæ¦‚ç‡
            log_prob = action_dist.log_prob(actions)
            log_probs.append(log_prob)
            
            # æ‰§è¡ŒåŠ¨ä½œ
            state, reward, done = self.env.step(actions)
            
            if done.all():
                rewards.append(reward)
                break
        
        # è®¡ç®—æ€»å¥–åŠ±
        total_rewards = rewards[-1] if rewards else torch.zeros(self.batch_size, self.pomo_size, device=self.device)
        
        # è®¡ç®—advantage
        baseline = total_rewards.mean(dim=1, keepdim=True)
        advantage = total_rewards - baseline
        
        # è®¡ç®—æ€»logæ¦‚ç‡
        total_log_prob = torch.stack(log_probs).sum(dim=0)
        
        # è®¡ç®—REINFORCEæŸå¤±
        rl_loss = -(advantage * total_log_prob).mean()
        
        # åå‘ä¼ æ’­
        self.optimizer.zero_grad()
        rl_loss.backward()
        self.optimizer.step()
        
        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        best_rewards = total_rewards.max(dim=1)[0]
        avg_reward = best_rewards.mean().item()
        avg_tour_length = -avg_reward
        
        self.global_step += 1
        
        return avg_tour_length, rl_loss.item()
    
    def train(self, num_epochs=1000, log_interval=10):
        """è®­ç»ƒä¸»å¾ªç¯"""
        self.logger.info("å¼€å§‹è®­ç»ƒæ‰©æ•£æ¨¡å‹+å¼ºåŒ–å­¦ä¹ ...")
        
        start_time = time.time()
        
        for epoch in range(num_epochs):
            # è®­ç»ƒæ¨¡å¼
            self.rl_model.train()
            self.diffusion_model.train()
            
            # è®­ç»ƒä¸€ä¸ªæ‰¹æ¬¡
            avg_length, total_loss = self.train_one_batch()
            
            # å­¦ä¹ ç‡è°ƒåº¦
            self.scheduler.step()
            
            # æ›´æ–°æœ€ä½³è®°å½•
            if avg_length < self.best_tour_length:
                self.best_tour_length = avg_length
            
            # è®°å½•æ—¥å¿—
            if epoch % log_interval == 0:
                elapsed_time = time.time() - start_time
                self.logger.info(f"Epoch {epoch:4d}: "
                               f"å¹³å‡è·¯å¾„é•¿åº¦={avg_length:.4f}, "
                               f"æ€»æŸå¤±={total_loss:.4f}, "
                               f"æœ€ä½³é•¿åº¦={self.best_tour_length:.4f}, "
                               f"ç”¨æ—¶={elapsed_time:.1f}s")
            
            # å®šæœŸè¯„ä¼°
            if epoch % 50 == 0:
                self.logger.info(f"è¿›è¡Œç¬¬{epoch}è½®è¯„ä¼°...")
                # åœ¨å•ä¸€æ¡ˆä¾‹æ¨¡å¼ä¸‹ï¼Œä½¿ç”¨æ›´å°çš„è¯„ä¼°é›†ä»¥åŠ å¿«è¯„ä¼°é€Ÿåº¦
                eval_instances = 1 if self.use_single_case else 100
                eval_length, is_best = self.evaluate(num_test_instances=eval_instances, visualize_solutions=True, max_visualizations=3)
                self.logger.info(f"è¯„ä¼°å®Œæˆï¼Œå¹³å‡è·¯å¾„é•¿åº¦: {eval_length:.4f}")
                
                # å¦‚æœæ˜¯æœ€ä½³ç»“æœï¼Œä¿å­˜æ¨¡å‹
                if is_best:
                    self.save_model(eval_length, epoch)
        
        # è®­ç»ƒç»“æŸ
        total_time = time.time() - start_time
        self.logger.info(f"è®­ç»ƒå®Œæˆï¼æ€»ç”¨æ—¶: {total_time:.1f}s")
        self.logger.info(f"æœ€ä½³è·¯å¾„é•¿åº¦: {self.best_tour_length:.4f}")
        
        # æœ€ç»ˆè¯„ä¼°
        final_eval_length, _ = self.evaluate(num_test_instances=100, visualize_solutions=True, max_visualizations=5)
        self.logger.info(f"æœ€ç»ˆè¯„ä¼°ç»“æœ: {final_eval_length:.4f}")
    
    def evaluate(self, num_test_instances=100, visualize_solutions=True, max_visualizations=5):
        """è¯„ä¼°æ¨¡å‹æ€§èƒ½ - ä½¿ç”¨æ‰©æ•£æ¨¡å‹çš„æµ‹è¯•æ•°æ®é›†"""
        self.logger.info("å¼€å§‹æ¨¡å‹è¯„ä¼°...")
        
        self.rl_model.eval()
        self.diffusion_model.eval()
        
        total_lengths = []
        total_gt_lengths = []
        solutions_to_visualize = []
        
        if self.use_single_case and self.fixed_case is not None:
            # å•ä¸€æ¡ˆä¾‹æ¨¡å¼ï¼šåªåœ¨å›ºå®šæ¡ˆä¾‹ä¸Šè¯„ä¼°
            self.logger.info("å•ä¸€æ¡ˆä¾‹è¯„ä¼°æ¨¡å¼")
            
            # å‡†å¤‡å›ºå®šæ¡ˆä¾‹æ•°æ®
            points = torch.from_numpy(self.fixed_case['points']).float().to(self.device)
            points = points.unsqueeze(0).repeat(self.batch_size, 1, 1)
            
            gt_tour = self.fixed_case['gt_tour']
            gt_length = self.fixed_case['gt_length']
            
            gt_lengths = [gt_length] * self.batch_size
            total_gt_lengths.extend(gt_lengths)
            
            with torch.no_grad():
                # ä½¿ç”¨æ‰©æ•£æ¨¡å‹ç”Ÿæˆé‚»æ¥çŸ©é˜µ
                adj_matrix = self.diffusion_model.generate_adj_tensor(points)
                
                # é‡ç½®ç¯å¢ƒ
                state = self.env.reset(points, adj_matrix)
                
                # è®°å½•è·¯å¾„
                batch_tours = [[[] for _ in range(self.pomo_size)] for _ in range(self.batch_size)]
                for b in range(self.batch_size):
                    for p in range(self.pomo_size):
                        batch_tours[b][p].append(0)  # èµ·å§‹èŠ‚ç‚¹
                
                # è´ªå¿ƒè§£ç 
                for step in range(self.num_nodes - 1):
                    logits = self.rl_model(state)
                    actions = logits.argmax(dim=-1)
                    
                    # è®°å½•è·¯å¾„
                    for b in range(self.batch_size):
                        for p in range(self.pomo_size):
                            batch_tours[b][p].append(actions[b, p].item())
                    
                    state, reward, done = self.env.step(actions)
                    
                    if done.all():
                        break
                
                # å®Œæˆç¯è·¯
                for b in range(self.batch_size):
                    for p in range(self.pomo_size):
                        batch_tours[b][p].append(0)  # å›åˆ°èµ·å§‹èŠ‚ç‚¹
                
                # æ”¶é›†æœ€ä¼˜è·¯å¾„é•¿åº¦ (æ³¨æ„ï¼šè¿™é‡Œæ˜¯è´Ÿçš„rewardï¼Œéœ€è¦å–å)
                best_lengths = (-state['tour_length']).max(dim=1)[0]
                total_lengths.extend(best_lengths.cpu().numpy())
                
                # ä¿å­˜è§£å†³æ–¹æ¡ˆç”¨äºå¯è§†åŒ–
                if visualize_solutions:
                    for b in range(min(self.batch_size, max_visualizations)):
                        best_pomo_idx = (-state['tour_length'][b]).argmax().item()
                        best_tour_length = (-state['tour_length'][b, best_pomo_idx]).item()
                        
                        solution_info = {
                            'points': points[b].cpu().numpy(),
                            'adj_matrix': adj_matrix[b].cpu().numpy(),
                            'tour_nodes': batch_tours[b][best_pomo_idx],
                            'tour_length': best_tour_length,
                            'gt_tour': gt_tour,
                            'gt_length': gt_length,
                        }
                        solutions_to_visualize.append(solution_info)
                        
        else:
            # åŸæ¥çš„å¤šæ¡ˆä¾‹è¯„ä¼°é€»è¾‘
            # è·å–æµ‹è¯•æ•°æ®åŠ è½½å™¨
            test_dataloader = self.diffusion_model.test_dataloader()
            self.logger.info(f"æµ‹è¯•æ•°æ®é›†å¤§å°: {len(test_dataloader)}")
            
            # é™åˆ¶æµ‹è¯•å®ä¾‹æ•°é‡
            max_batches = min(num_test_instances // self.batch_size, len(test_dataloader))
            
            with torch.no_grad():
                for batch_idx, batch in enumerate(test_dataloader):
                    if batch_idx >= max_batches:
                        break
                    
                # è§£ææµ‹è¯•æ•°æ®ï¼ˆå‚è€ƒdifusion_tool.pyä¸­çš„æ ¼å¼ï¼‰
                if not self.diffusion_model.sparse:
                    real_batch_idx, points, adj_matrix_gt, gt_tour = batch
                    # ç§»åŠ¨åˆ°æ­£ç¡®çš„è®¾å¤‡
                    points = points.to(self.device)
                    gt_tour = gt_tour.to(self.device)
                    
                    # åªå–ç¬¬ä¸€ä¸ªå®ä¾‹ï¼ˆæµ‹è¯•æ—¶batch_sizeé€šå¸¸ä¸º1ï¼‰
                    if points.shape[0] == 1:
                        points = points.repeat(self.batch_size, 1, 1)
                        gt_tour = gt_tour.repeat(self.batch_size, 1)
                    else:
                        # å¦‚æœbatchå¤§å°ä¸åŒ¹é…ï¼Œæˆªå–æˆ–å¡«å……
                        if points.shape[0] < self.batch_size:
                            points = points[:1].repeat(self.batch_size, 1, 1)
                            gt_tour = gt_tour[:1].repeat(self.batch_size, 1)
                        else:
                            points = points[:self.batch_size]
                            gt_tour = gt_tour[:self.batch_size]
                else:
                    # å¤„ç†ç¨€ç–æ ¼å¼ï¼ˆå¦‚æœéœ€è¦ï¼‰
                    real_batch_idx, graph_data, point_indicator, edge_indicator, gt_tour = batch
                    points = graph_data.x.reshape((-1, self.num_nodes, 2))
                    gt_tour = gt_tour.reshape(-1, self.num_nodes)
                    
                    # ç§»åŠ¨åˆ°æ­£ç¡®çš„è®¾å¤‡å¹¶å¤„ç†batchå¤§å°
                    points = points.to(self.device)
                    gt_tour = gt_tour.to(self.device)
                    
                    if points.shape[0] < self.batch_size:
                        points = points[:1].repeat(self.batch_size, 1, 1)
                        gt_tour = gt_tour[:1].repeat(self.batch_size, 1)
                    else:
                        points = points[:self.batch_size]
                        gt_tour = gt_tour[:self.batch_size]
                
                # è®¡ç®—çœŸå®æœ€ä¼˜è§£çš„æˆæœ¬
                gt_lengths = []
                for b in range(points.shape[0]):
                    gt_tour_b = gt_tour[b].cpu().numpy()
                    points_b = points[b].cpu().numpy()
                    
                    # è®¡ç®—çœŸå®æœ€ä¼˜è·¯å¾„çš„æˆæœ¬
                    gt_cost = 0.0
                    for i in range(len(gt_tour_b)):
                        start_node = gt_tour_b[i]
                        end_node = gt_tour_b[(i + 1) % len(gt_tour_b)]
                        distance = np.sqrt(np.sum((points_b[start_node] - points_b[end_node]) ** 2))
                        gt_cost += distance
                    gt_lengths.append(gt_cost)
                
                total_gt_lengths.extend(gt_lengths)
                
                # ä½¿ç”¨æ‰©æ•£æ¨¡å‹ç”Ÿæˆé‚»æ¥çŸ©é˜µ
                adj_matrix = self.diffusion_model.generate_adj_tensor(points)
                
                # é‡ç½®ç¯å¢ƒ
                state = self.env.reset(points, adj_matrix)
                
                # è®°å½•è·¯å¾„
                batch_tours = [[[] for _ in range(self.pomo_size)] for _ in range(self.batch_size)]
                for b in range(self.batch_size):
                    for p in range(self.pomo_size):
                        batch_tours[b][p].append(0)  # èµ·å§‹èŠ‚ç‚¹
                
                # è´ªå¿ƒè§£ç 
                for step in range(self.num_nodes - 1):
                    logits = self.rl_model(state)
                    actions = logits.argmax(dim=-1)
                    
                    # è®°å½•è·¯å¾„
                    for b in range(self.batch_size):
                        for p in range(self.pomo_size):
                            batch_tours[b][p].append(actions[b, p].item())
                    
                    state, reward, done = self.env.step(actions)
                    
                    if done.all():
                        break
                
                # å®Œæˆç¯è·¯
                for b in range(self.batch_size):
                    for p in range(self.pomo_size):
                        batch_tours[b][p].append(0)  # å›åˆ°èµ·å§‹èŠ‚ç‚¹
                
                # æ”¶é›†æœ€ä¼˜è·¯å¾„é•¿åº¦ (æ³¨æ„ï¼šè¿™é‡Œæ˜¯è´Ÿçš„rewardï¼Œéœ€è¦å–å)
                best_lengths = (-state['tour_length']).max(dim=1)[0]
                total_lengths.extend(best_lengths.cpu().numpy())
                
                # ä¿å­˜è§£å†³æ–¹æ¡ˆç”¨äºå¯è§†åŒ–
                if visualize_solutions and len(solutions_to_visualize) < max_visualizations:
                    for b in range(min(self.batch_size, max_visualizations - len(solutions_to_visualize))):
                        best_pomo_idx = (-state['tour_length'][b]).argmax().item()
                        best_tour_length = (-state['tour_length'][b, best_pomo_idx]).item()
                        
                        solution_info = {
                            'points': points[b].cpu().numpy(),
                            'adj_matrix': adj_matrix[b].cpu().numpy(),
                            'tour_nodes': batch_tours[b][best_pomo_idx],
                            'tour_length': best_tour_length,
                            'gt_tour': gt_tour[b].cpu().numpy(),
                            'gt_length': gt_lengths[b],
                        }
                        solutions_to_visualize.append(solution_info)
        
        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        avg_length = np.mean(total_lengths)
        std_length = np.std(total_lengths)
        min_length = np.min(total_lengths)
        max_length = np.max(total_lengths)
        
        # è®¡ç®—ä¸æœ€ä¼˜è§£çš„æ¯”è¾ƒ
        avg_gt_length = np.mean(total_gt_lengths)
        gap_values = [(pred - gt) / gt * 100 for pred, gt in zip(total_lengths, total_gt_lengths)]
        avg_gap = np.mean(gap_values)
        std_gap = np.std(gap_values)
        
        # æ£€æŸ¥æ˜¯å¦ä¸ºæœ€ä½³ç»“æœ
        is_best = avg_length < self.best_eval_length
        if is_best:
            self.best_eval_length = avg_length
            self.logger.info(f"å‘ç°æ–°çš„æœ€ä½³è¯„ä¼°ç»“æœ! å¹³å‡è·¯å¾„é•¿åº¦: {avg_length:.4f}")
        
        # å¯è§†åŒ–è§£å†³æ–¹æ¡ˆ
        if visualize_solutions and solutions_to_visualize:
            self.logger.info(f"æ­£åœ¨å¯è§†åŒ– {len(solutions_to_visualize)} ä¸ªè¯„ä¼°è§£å†³æ–¹æ¡ˆ...")
            self.visualize_solutions(solutions_to_visualize, avg_length, is_best)
        
        self.logger.info(f"è¯„ä¼°ç»“æœ - é¢„æµ‹å¹³å‡é•¿åº¦: {avg_length:.4f} Â± {std_length:.4f}")
        self.logger.info(f"è¯„ä¼°ç»“æœ - æœ€ä¼˜å¹³å‡é•¿åº¦: {avg_gt_length:.4f}")
        self.logger.info(f"è¯„ä¼°ç»“æœ - ç›¸å¯¹å·®è·: {avg_gap:.2f}% Â± {std_gap:.2f}%")
        self.logger.info(f"è¯„ä¼°ç»“æœ - é•¿åº¦èŒƒå›´: [{min_length:.4f}, {max_length:.4f}]")
        
        return avg_length, is_best
    
    def visualize_solutions(self, solutions, avg_length, is_best):
        """å¯è§†åŒ–è¯„ä¼°è¿‡ç¨‹ä¸­çš„è§£å†³æ–¹æ¡ˆ"""
        try:
            import matplotlib.pyplot as plt
            
            # æ‰¾åˆ°æœ€ä½³å’Œæœ€å·®çš„è§£å†³æ–¹æ¡ˆ
            best_solution = min(solutions, key=lambda x: x['tour_length'])
            worst_solution = max(solutions, key=lambda x: x['tour_length'])
            
            # åˆ›å»ºå¤šå­å›¾å±•ç¤º
            n_solutions = min(len(solutions), 4)
            fig, axes = plt.subplots(2, 2, figsize=(16, 12))
            axes = axes.flatten()
            
            solutions_to_show = [best_solution, worst_solution] + solutions[:2] if len(solutions) > 2 else solutions
            
            for i, solution in enumerate(solutions_to_show[:n_solutions]):
                ax = axes[i]
                
                points_np = solution['points']
                tour_nodes = solution['tour_nodes']
                tour_length = solution['tour_length']
                
                # è·å–çœŸå®æœ€ä¼˜è§£ä¿¡æ¯
                gt_tour = solution.get('gt_tour', None)
                gt_length = solution.get('gt_length', None)
                
                # ç»˜åˆ¶èŠ‚ç‚¹
                ax.scatter(points_np[:, 0], points_np[:, 1], c='red', s=60, zorder=3)
                
                # æ ‡æ³¨èŠ‚ç‚¹ç¼–å·
                for j, (x, y) in enumerate(points_np):
                    ax.annotate(str(j), (x, y), xytext=(3, 3), textcoords='offset points', 
                              fontsize=7, fontweight='bold')
                
                # ç»˜åˆ¶çœŸå®æœ€ä¼˜è·¯å¾„ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                if gt_tour is not None:
                    gt_tour_coords = points_np[gt_tour]
                    
                    # ç»˜åˆ¶æœ€ä¼˜è·¯å¾„çº¿æ®µï¼ˆç»¿è‰²è™šçº¿ï¼‰
                    for j in range(len(gt_tour)):
                        start_point = gt_tour_coords[j]
                        end_point = gt_tour_coords[(j + 1) % len(gt_tour)]
                        ax.plot([start_point[0], end_point[0]], [start_point[1], end_point[1]], 
                               'g--', linewidth=2, alpha=0.8, zorder=1, label='æœ€ä¼˜è§£' if j == 0 else "")
                
                # ç»˜åˆ¶é¢„æµ‹çš„TSPè·¯å¾„ï¼ˆè“è‰²å®çº¿ï¼‰
                tour_coords = points_np[tour_nodes]
                
                # ç»˜åˆ¶è·¯å¾„çº¿æ®µ
                for j in range(len(tour_nodes) - 1):
                    start_point = tour_coords[j]
                    end_point = tour_coords[j + 1]
                    ax.plot([start_point[0], end_point[0]], [start_point[1], end_point[1]], 
                           'b-', linewidth=1.5, alpha=0.7, zorder=2, label='é¢„æµ‹è§£' if j == 0 else "")
                
                # é«˜äº®èµ·å§‹èŠ‚ç‚¹
                start_point = points_np[0]
                circle = plt.Circle((start_point[0], start_point[1]), 0.025, 
                                  color='orange', fill=True, zorder=4)
                ax.add_patch(circle)
                
                # è®¾ç½®æ ‡é¢˜
                if i == 0 and solution == best_solution:
                    title_prefix = "ğŸ† æœ€ä½³è§£"
                elif i == 1 and solution == worst_solution:
                    title_prefix = "ğŸ“‰ æœ€å·®è§£"
                else:
                    title_prefix = f"è§£å†³æ–¹æ¡ˆ #{i+1}"
                
                # è®¡ç®—ç›¸å¯¹å·®è·
                if gt_length is not None:
                    gap = (tour_length - gt_length) / gt_length * 100
                    title_text = f'{title_prefix}\né¢„æµ‹: {tour_length:.3f} | æœ€ä¼˜: {gt_length:.3f}\nå·®è·: {gap:.2f}%'
                else:
                    title_text = f'{title_prefix}\né•¿åº¦: {tour_length:.3f}'
                    
                ax.set_title(title_text, fontsize=10)
                ax.set_xlabel('Xåæ ‡', fontsize=8)
                ax.set_ylabel('Yåæ ‡', fontsize=8)
                ax.grid(True, alpha=0.3)
                ax.set_aspect('equal')
                
                # æ·»åŠ å›¾ä¾‹ï¼ˆä»…ä¸ºç¬¬ä¸€ä¸ªå­å›¾ï¼‰
                if i == 0 and gt_tour is not None:
                    ax.legend(loc='upper right', fontsize=8)
            
            # éšè—æœªä½¿ç”¨çš„å­å›¾
            for i in range(n_solutions, 4):
                axes[i].set_visible(False)
            
            # è®¡ç®—æ€»ä½“å·®è·ä¿¡æ¯
            avg_gt_length = np.mean([s.get('gt_length', 0) for s in solutions if s.get('gt_length') is not None])
            if avg_gt_length > 0:
                overall_gap = (avg_length - avg_gt_length) / avg_gt_length * 100
                gap_info = f" | å¹³å‡å·®è·: {overall_gap:.2f}%"
            else:
                gap_info = ""
            
            # è®¾ç½®æ€»æ ‡é¢˜
            best_indicator = " ğŸ† æ–°æœ€ä½³!" if is_best else ""
            fig.suptitle(f'è¯„ä¼°è§£å†³æ–¹æ¡ˆå¯è§†åŒ–{best_indicator}\nå¹³å‡é•¿åº¦: {avg_length:.4f}{gap_info} | æ­¥éª¤: {self.global_step}', 
                        fontsize=14, fontweight='bold')
            
            plt.tight_layout()
            
            # ä¿å­˜å›¾ç‰‡
            os.makedirs('results', exist_ok=True)
            plt.savefig(f'results/solutions_step_{self.global_step}.png', dpi=300, bbox_inches='tight')
            self.logger.info(f"ä¿å­˜å¯è§†åŒ–ç»“æœåˆ°: results/solutions_step_{self.global_step}.png")
            
            plt.close(fig)
            
        except Exception as e:
            self.logger.warning(f"å¯è§†åŒ–å¤±è´¥: {e}")
    
    def save_model(self, eval_length, epoch):
        """ä¿å­˜æœ€ä½³æ¨¡å‹"""
        os.makedirs('saved_models', exist_ok=True)
        
        model_data = {
            'epoch': epoch,
            'eval_length': eval_length,
            'rl_model_state_dict': self.rl_model.state_dict(),
            'diffusion_model_state_dict': self.diffusion_model.state_dict(),
            'optimizer_state_dict': self.optimizer.state_dict(),
        }
        
        model_path = 'saved_models/best_model.pt'
        torch.save(model_data, model_path)
        self.logger.info(f"ä¿å­˜æœ€ä½³æ¨¡å‹: {model_path} (è¯„ä¼°é•¿åº¦: {eval_length:.4f})")


def create_logger():
    """åˆ›å»ºæ—¥å¿—å™¨"""
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )


def main():
    """ä¸»å‡½æ•°"""
    create_logger()
    
    # è®­ç»ƒå‚æ•°
    diffusion_model_path = 'tb_logs/tsp_diffusion/version_0/checkpoints/last.ckpt'
    
    # åˆ›å»ºè®­ç»ƒå™¨ - å¯ç”¨å•ä¸€æ¡ˆä¾‹è®­ç»ƒæ¨¡å¼
    trainer = DiffusionRLTrainer(
        diffusion_model_path=diffusion_model_path,
        num_nodes=50,
        batch_size=8,  # å‡å°batch sizeä»¥ä¾¿è§‚å¯Ÿå•ä¸€æ¡ˆä¾‹çš„è®­ç»ƒæ•ˆæœ
        pomo_size=50,
        lr=1e-3,  # æé«˜å­¦ä¹ ç‡ä»¥åŠ å¿«åœ¨å•ä¸€æ¡ˆä¾‹ä¸Šçš„æ”¶æ•›
        device='cuda' if torch.cuda.is_available() else 'cpu',
        use_single_case=True,  # æ˜ç¡®å¯ç”¨å•ä¸€æ¡ˆä¾‹æ¨¡å¼
        use_linear_enhancement=False  # çº¿æ€§å±‚å¢å¼ºæ¨¡å¼ï¼šTrue=å¯ç”¨ï¼ŒFalse=çº¯é‚»æ¥çŸ©é˜µæ¨¡å¼
    )
    
    # åœ¨è®­ç»ƒå‰å…ˆè¯„ä¼°ä¸€æ¬¡ï¼Œçœ‹çœ‹åˆå§‹æ€§èƒ½
    trainer.logger.info("=== è®­ç»ƒå‰åˆå§‹è¯„ä¼° ===")
    initial_eval_length, _ = trainer.evaluate(num_test_instances=1, visualize_solutions=True, max_visualizations=5)
    trainer.logger.info(f"åˆå§‹è¯„ä¼°ç»“æœ: {initial_eval_length:.4f}")
    
    # å¼€å§‹è®­ç»ƒ - ä½¿ç”¨æ›´é¢‘ç¹çš„æ—¥å¿—å’Œè¯„ä¼°
    trainer.train(num_epochs=200, log_interval=5)  # æ›´é¢‘ç¹çš„æ—¥å¿—è®°å½•
    
    # è®­ç»ƒåæœ€ç»ˆè¯„ä¼°
    trainer.logger.info("=== è®­ç»ƒåæœ€ç»ˆè¯„ä¼° ===")
    final_eval_length, _ = trainer.evaluate(num_test_instances=1, visualize_solutions=True, max_visualizations=5)
    trainer.logger.info(f"æœ€ç»ˆè¯„ä¼°ç»“æœ: {final_eval_length:.4f}")
    trainer.logger.info(f"ç›¸å¯¹æ”¹è¿›: {((initial_eval_length - final_eval_length) / initial_eval_length * 100):.2f}%")


if __name__ == "__main__":
    main() 